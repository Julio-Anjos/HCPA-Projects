
* Definições
** Conceitos biologia

  - Nucleotídeo: Molécula orgânica formada por um nucleosídeo e um fosfato
    Existem quatro tipos de nucleotídeos no código genético (AGTU)
  - Codon: Tripla de nucleotídeos Existem 4^3 = 64 codons possíveis
  - Polímero: Substância composta por diversas moléculas em grupos repetidos
    (chamados monômeros)
  - Polinucleotídeo: Polímero de 13 ou mais nucleotídeos interligados
    covalentemente em uma cadeia
  - RNA: Composto orgânico de uma cadeia de polinucleotídeos encadeados entre
    si É geradao a partir do DNA por uma enzima chamada RNA-polimerase num
    processo chamado de *transcrição*
  - DNA: Composto orgânico de duas cadeias de polinucleotídeos encadeados em
    uma hélice dupla
  - Ácido nucléico: Uma classe de polinucleotídeos incluindo DNA e RNA
  - Aminoácido: Composto orgânico contendo grupos funcionais de amina e ácido
    carboxílico, e um grupo substituto (R) específico de cada aminoácido Podem
    ser classificados pela localização dos seus grupos funcionais como \alpha,
    \beta, \gamma, ou \delta.  Apenas 20 aminoácidos diferentes compõem
    proteínas em seres vivos
  - Proteína: Composto orgânico de vários aminoácidos
  - Ribossomo: Estrutura sub-celular que realiza a síntese proteica tendo o
    mRNA como mnemônico (fase de *tradução*)
  - mRNA: O RNA lido pelo ribossomo para determinar quais proteínas sintetizar
  - tRNA: O RNA utilizado para entregar aminoácidos ao ribossomo
  - rRNA: O RNA usado para ligar aminoácidos entre si para formar proteínas

  (!) Cada codon presente no mRNA determina a síntese de um aminoácido
  específico No código genético, 61 codons traduzem para aminoácidos
  específicos, os outros são "stop codons" (sinalizadores) Dado que há 61
  códons mas apenas 20 aminoácidos, a maioria dos aminoácidos é traduzida por
  mais de um códon Isso permite que substituições no DNA não produzam uma
  alteração nos aminoácidos correspondentes Essas *substituições* são chamadas
  de *sinônimas* ou silenciosas, enquanto as que modificam são *não-sinônimas*
  Acredita-se que as substituições sinônimas sejam mais comuns e não sofram
  tanta pressão seletiva A *taxa de substituiçõs sinônimas e não sinônimas*
  \omega = dN/dS é uma medida de seleção natual:[1]

        - \omega = 1 indica evolução neutra
        - \omega > 1 indica seleção purificadora ou negativa
        - \omega < 1 indica seleção positiva

  - Gene: Sequência de nucleotídeos no DNA ou RNA que codifica a síntese de um
    produto genético: RNA ou uma proteína
  - Expressão genética: Uso de um gene para gerar um produto (e.g. síntese
    protéica)
  - Alelos: Dois genes que expressam a mesma coisa
  - Seleção purificadora ou negativa: Remoção de alelos nocivos
  - Seleção positiva: Adição de alelos benéficos
  - *Análise filogenética*: O estudo da evolução de um ou mais organismos ou de
    suas características

** PAML e codeml

  (!) Alguns estudos medem seleção positiva comparando pares de DNA para
  estimar as taxas de substituição sob todos sítios.  Todavia, devido a
  limitações estruturais e funcionais a evolução afeta somente alguns síteos
  proteicos.  O software PAML utiliza modelos de substituição de códon em que
  \omega varia ao longo de síteos e linhagens.

  No software, os _branch models_ permitem variar \omega entre diversas
  ramificações da filogenia.  Os _site models_ permitem variar \omega entre
  sites (entre codons ou aminoácidos na proteína). Diversos modelos são
  implementados no codeml usando a variável Nssites e model=0.

  (!) O codeml usa métodos de maximum-likelihood, um problema de otimização
  multi-dimensional resolvido numericamente. O PAML implementa dois algoritmos
  iterativos: O primeiro (method=0) é um algoritmo de minimização de propósito
  geral que faz uso de derivadas de primeiro grau determinadas através de
  diferenças finitas (paralilizável!) e de segundo grau (determinadas usando
  BFGS).  O segundo (method=1) Usa BFGS de forma iterada até a convergência ser
  atingida, e uma fase de otimização de ramificações é realizada
  sequencialmente para cada ramificação (branch) até todas serem otimizadas.
  Manual diz que estimativas são correlacionadas.

  > codeml is a part of the PAML package, which is a suite of programs for
  > phylogenetic analyses of DNA or protein sequences using maximum likelihood
  > (ML).
  > 
  > In simple words, the aim of codeml is to detect positive selection events
  > in the history of species.
  > 
  > With the seqtype set to 1, codeml carries out ML analysis of protein-coding
  > DNA sequences using codon substitution models (e.g., Goldman and Yang
  > 1994). With seqtype set to 2, codeml carries out ML analysis of amino acid
  > sequences under a number of amino acid substitution models.
  
*** Formatos de entrada

- Arquivo de sequência
  - Formato: PHYLIP
  - Spec: http://scikit-bio.org/docs/0.2.3/generated/skbio.io.phylip.html

- Arquivo de árvore
  - Formato: Newick format (https://en.wikipedia.org/wiki/Newick_format)
  - Especificação: http://abacus.gene.ucl.ac.uk/software/pamlDOC.pdf
  - Visualizador: http://etetoolkit.org/treeview/

Os nomes no arquivo de árvore devem bater com os nomes no arquivo de sequência!

*** Algoritmos usados

  - Monte Carlo
    - Paralelizável: Sim
    - Local onde é usado: ?

  - Maximum-Likelihood: Usa diferenças finitas etc, vide abaixo

  - Diferenças finitas
    - Paralelizável: Sim
    - Local onde é usado: codml

  - Broyden–Fletcher–Goldfarb–Shanno (BFGS)
    - Paralelizável: Sim?
    - Local onde é usado: codml

  - Naive Empirical Bayesian?

  - Bayes Empirical Bayesian?

  - Markov models of codon substitution?

  - Star decomposition
    - Paralelizável: ?
    - Local onde é usado: baseml e codonml

  - Stepwise addition?

  - Nearest Neighbor?

* Notas

** Julho

*** Semana 1

**** Resumo executivo

Foi obtido o código, os dados, e o estudo inicial feito na cadeira de PDP. Foi
estudado o pacote PAML e seu manual, o código, algoritmos utilizados e áreas de
potencial paralelização, conceitos de biologia, e literatura relacionada ao
codeml. Foi organizado este documento e um repositório git. Foi realizada
reunião com Julio e Agnis para entender o caso de uso do hospital, reportar o
trabalho feito até então e os próximos passos.

*** Semana 2

**** Resumo executivo

Perfilei a implementação sequencial do codeml na infra do PCAD (beagle)
utilizando gprof e callgrind, com resultados semelhantes (anexo).

Verifiquei que algumas das rotinas responsáveis pela maior parte do tempo de
execução implementam métodos numéricos paralelizáveis, como diferenças finitas
em "gradientB" e BFGS em "ming2".

Paralelizei a gradientB com OpenMP e implementei testes unitários para garantir
a corretude da implementação paralela. 

O codeml paralelo fica em laço pois o método não converge mais. O problema são
as funções passadas ao gradientB (cujo gradiente está sendo calculado), que não
são thread-safe. A paralelização em si está correta.

Como próximos passos pretendo avaliar tornar tais funções thread-safe, bem como
estudar mais a fundo a ming2 a fim de explorar novas estratégias de
paralelização, focando nas sub-rotinas mais chamadas.

**** Notas completas

O objetivo inicial é perfilar a execução sequencial com os dados de entrada
fornecidos pelo Julio.

Os arquivos de entrada fornecidos não são aceitos pelo codeml, que retorna uma
mensagem de erro informando que, no arquivo de sequência, o nome das sequências
deve estar separado por pelo menos dois espaços do resto da sequência. O
arquivo fornecido foi editado de acordo para superar esse entrave. O arquivo
codeml.clt referenciava um arquivo inexistente e foi ajustado. Ainda assim, o
codeml reclama que as espécies descritas no arquivo de árvore não estão
presentes no arquivo de sequência.

Dessa forma o objetivo passou a ser perfilar a execução sequencial com um dos
exemplos fornecidos junto ao codeml, em paralelo a alinhar com Julio e Agnis os
problemas com os dados originais.

Inicialmente pretendo utilizar três técnicas para perfil da aplicação, em paralelo:

- gprof
- callgrind + kcachegrind (valgrind)
- logs de execução (printf) 

Para tal foi desenvolvido um script de perfilamento e executado o
perfil com gprof em minha máquina pessoal e com callgrind na beagle do
PCAD, pois o tempo de execução passa de 11min para 7h22m com o
valgrind (para o dataset de exemplo "MHC"). Resultados:

[[FILE:img/example_results.gif]]

Como pode ser visto na imagem acima, os resultados apresentados pelo
gprof e pelo callgrind são bem diferentes. Como podemos ver na
documentação do código, a função =minB=, uma das responsáveis pela
maior parte do tempo de execução no gprof, chama =ming2=, uma das
vilãs no kcachegrind:

#+BEGIN_EXAMPLE
int minB(FILE*fout, double *lnL, double x[], double xb[][2], double e0, double space[])
{
   /* This calculates lnL for given values of common parameters by optimizing
    branch lengths, cycling through them.
    Z. Yang, November 1999
    This calls minbranches to optimize branch lengths and ming2 to
    estimate other paramters.
    At the end of the routine, there is a call to lfun to restore nodes[].conP.
    Returns variances of branch lengths in space[].
    space[] is com.space[].  com.space may be reallocated here, which may be unsafe
    as the pointers in the calling routine may not be pointing to the right places.
#+END_EXAMPLE

De qualquer forma achei estranho a diferença nos resultados e resolvi rodar o
gprof na beagle também - como há bastante I/O e no PCAD é um NFS, talvez isso
tenha impactado os resultados... Rodando na beagle os resultados são mais
semelhantes ao do callgrind:

#+BEGIN_EXAMPLE
Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls   s/call   s/call  name    
 69.01    632.83   632.83     5499     0.12     0.17  ConditionalPNode
 30.04    908.28   275.44  2095119     0.00     0.00  PMatUVRoot
  0.38    911.73     3.46    54990     0.00     0.00  NodeScale
  0.26    914.11     2.38     5499     0.00     0.00  EigenTridagQLImplicit
  0.15    915.45     1.34     5499     0.00     0.00  HouseholderRealSym
  0.10    916.35     0.90        2     0.45     1.69  get_pclassM_iw_M2M8
  0.02    916.53     0.18   215822     0.00     0.00  PDFt
  0.01    916.64     0.11     5499     0.00     0.00  eigenQREV
  0.01    916.75     0.11     6681     0.00     0.00  eigenQcodon
  0.01    916.85     0.10      777     0.00     1.16  fx_r
  0.00    916.89     0.04  2095119     0.00     0.00  GetPMatBranch
  0.00    916.92     0.03     5499     0.00     0.00  eigenRealSym
  0.00    916.94     0.02      768     0.00     0.00  AddCodonFreqSeqGene
  0.00    916.95     0.01   656646     0.00     0.00  NucListall
  0.00    916.96     0.01      381     0.00     0.00  GetSNphysical
  0.00    916.97     0.01        4     0.00     2.01  lfunNSsites_rate
  0.00    916.97     0.01                             InitializeNodeScale
  0.00    916.98     0.01                             SelectionCoefficients
  0.00    916.98     0.00  1469020     0.00     0.00  GetOmega
  0.00    916.98     0.00  1188720     0.00     0.00  LnGamma
  0.00    916.98     0.00   408148     0.00     0.00  sum
  0.00    916.98     0.00   184128     0.00     0.00  GetAASiteSpecies
  0.00    916.98     0.00   180000     0.00     0.00  CDFBeta
  0.00    916.98     0.00    30000     0.00     0.00  GetIndexTernary
  0.00    916.98     0.00     5427     0.00     0.00  SetPSiteClass
  0.00    916.98     0.00     4180     0.00     0.00  CDFt
#+END_EXAMPLE

#+BEGIN_EXAMPLE
                     Call graph (explanation follows)


granularity: each sample hit covers 2 byte(s) for 0.00% of 916.98 seconds

index % time    self  children    called     name
                                                 <spontaneous>
[1]    100.0    0.00  916.94                 Forestry [1]
                0.00  899.02       5/5           ming2 [4]
                0.00    9.30       8/771         lfundG [5]
                0.01    8.03       4/4           lfunNSsites_rate [11]
                0.00    0.33       2/72          lfun [10]
                0.00    0.24       5/5           DetailOutput [22]
                0.00    0.00      15/15          OutSubTreeN [52]
                0.00    0.00       5/5           GetTreeFileType [63]
                0.00    0.00       5/6           gfopen [59]
                0.00    0.00       5/5           ReadTreeN [64]
                0.00    0.00       5/5           GetInitials [60]
                0.00    0.00       5/5           SetxBound [66]
                0.00    0.00       5/5           SetxInitials [68]
                0.00    0.00       5/1113        matout [41]
                0.00    0.00       1/223         f_and_x [45]
-----------------------------------------------
#+END_EXAMPLE

A julgar pela documentação do código, ming2 é paralelizável:

#+BEGIN_EXAMPLE
int ming2(FILE *fout, double *f, double(*fun)(double x[], int n),
   int(*dfun)(double x[], double *f, double dx[], int n),
   double x[], double xb[][2], double space[], double e, int n)
{
   /* n-variate minimization with bounds using the BFGS algorithm
        g0[n] g[n] p[n] x0[n] y[n] s[n] z[n] H[n*n] C[n*n] tv[2*n]
        xmark[n],ix[n]
      Size of space should be (check carefully?)
         #define spaceming2(n) ((n)*((n)*2+9+2)*sizeof(double))
      nfree: # free variables
      xmark[i]=0 for inside space; -1 for lower boundary; 1 for upper boundary.
      x[] has initial values at input and returns the estimates in return.
      ix[i] specifies the i-th free parameter

   */
#+END_EXAMPLE

#+BEGIN_EXAMPLE
double LineSearch2(double(*fun)(double x[], int n), double *f, double x0[],
   double p[], double step, double limit, double e, double space[], int n)
{
   /* linear search using quadratic interpolation
      from x0[] in the direction of p[],
                   x = x0 + a*p        a ~(0,limit)
      returns (a).    *f: f(x0) for input and f(x) for output

      x0[n] x[n] p[n] space[n]

      adapted from Wolfe M. A.  1978.  Numerical methods for unconstrained
      optimization: An introduction.  Van Nostrand Reinhold Company, New York.
      pp. 62-73.
      step is used to find the bracket and is increased or reduced as necessary,
      and is not terribly important.
   */
#+END_EXAMPLE

#+BEGIN_EXAMPLE
int gradientB(int n, double x[], double f0, double g[],
   double(*fun)(double x[], int n), double space[], int xmark[])
{
   /* f0=fun(x) is always provided.
   xmark=0: central; 1: upper; -1: down
   */
   int i, j;
   double *x0 = space, *x1 = space + n, eh0 = Small_Diff, eh;  /* eh0=1e-6 || 1e-7 */

   for (i = 0; i < n; i++) {
      eh = eh0*(fabs(x[i]) + 1);
      if (xmark[i] == 0 && (AlwaysCenter || SIZEp < 1)) {   /* central */
         for (j = 0; j < n; j++)  x0[j] = x1[j] = x[j];
         eh = pow(eh, .67);   x0[i] -= eh;  x1[i] += eh;
         g[i] = ((*fun)(x1, n) - (*fun)(x0, n)) / (eh*2.0);
      }
      else {                                              /* forward or backward */
         for (j = 0; j < n; j++)  x1[j] = x[j];
         if (xmark[i]) eh *= -xmark[i];
         x1[i] += eh;
         g[i] = ((*fun)(x1, n) - f0) / eh;
      }
   }
   return(0);
}
#+END_EXAMPLE

BFSG é paralelizável:

- https://www.sciencedirect.com/science/article/abs/pii/S0097849314000119
- https://arxiv.org/abs/2011.00667
- https://pypi.org/project/optimparallel/

A função gradientB está executando diferenças finitas, o que é
parelilizável (já fiz no programa utilizado na TF de PDP, de difusão
de calor).

Não encontrei muitos detalhes sobre o algoritmo utilizado em
LineSearch2, o livro onde está descrito não há PDF online, sendo
necessário adquirir, e não achei muito sobre essa implementação na
internet.

Paralelizei e escrevi testes unitários para a função gradientB, e
refiz o perfil com a função paralelizada.

Claramente minha aplicaçõa entrou em laço, apesar da minha paralelização estar
correta cf. testes unitários:

#+BEGIN_EXAMPLE
Iterating by ming2
Initial: fx=  8238.995628
x=  1.60000  0.90000
thread=0; type=fwbw; g[0]=-18.478365; x1=0
thread=0; type=fwbw; g[1]=68.883013; x1=0

  1 h-m-p  0.0000 0.0131  71.3184 ++++CYCCCC  8225.424791  5 0.0043    20thread=0; type=fwbw; g[0]=-6.786824; x1=0
thread=0; type=fwbw; g[1]=-1.845802; x1=0
 | 0/2
  2 h-m-p  0.0431 8.0000   7.0650 CC     8225.163949  1 0.0107    27thread=0; type=fwbw; g[0]=-0.416620; x1=0
thread=0; type=fwbw; g[1]=2.813778; x1=0
 | 0/2
  3 h-m-p  1.6000 8.0000   0.0131 CC     8225.154796  1 0.5424    34thread=0; type=central; g[0]=-0.031600; x0=0; x1=16
thread=0; type=central; g[1]=-0.017255; x0=0; x1=16
 | 0/2
  4 h-m-p  1.6000 8.0000   0.0004 Y      8225.154790  0 1.0672    41thread=0; type=central; g[0]=0.000355; x0=0; x1=16
thread=0; type=central; g[1]=-0.002415; x0=0; x1=16
#+END_EXAMPLE

#+BEGIN_EXAMPLE
Iterating by ming2
Initial: fx=  8238.995628
x=  1.60000  0.90000
thread=0; type=fwbw; g[0]=-nan; x1=0
thread=1; type=fwbw; g[1]=-nan; x1=32
                                                                                                                                               t
  1 h-m-p  0.0040 8.0000     -nan ++++++         -nan  m 8.0000    11thread=0; type=fwbw; g[0]=nan; x1=0
thread=1; type=fwbw; g[1]=nan; x1=32
 | 0/2
  2 h-m-p  0.0160 8.0000      nan +++++          nan  m 8.0000    19thread=0; type=fwbw; g[0]=nan; x1=0
thread=1; type=fwbw; g[1]=nan; x1=32                                                                                                           t
 | 0/2
  3 h-m-p  0.0160 8.0000      nan +++++          nan  m 8.0000    27thread=0; type=fwbw; g[0]=nan; x1=0
thread=1; type=fwbw; g[1]=nan; x1=32
 | 0/2
  4 h-m-p  0.0160 8.0000      nan +++++          nan  m 8.0000    35thread=0; type=fwbw; g[0]=nan; x1=0
thread=1; type=fwbw; g[1]=nan; x1=32
 | 0/2
  5 h-m-p  0.0160 8.0000      nan +++++          nan  m 8.0000    43thread=0; type=fwbw; g[0]=nan; x1=0
thread=1; type=fwbw; g[1]=nan; x1=32
 | 0/2

 # Interrompido, se repete pra sempre

#+END_EXAMPLE

O problema é que a função sendo derivada é implementada de forma não
thread-safe. P.e. ConditionalPNode que é chamada dentro de lfun:

#+BEGIN_EXAMPLE
int ConditionalPNode(int inode, int igene, double x[])
{
   int n = com.ncode, i, j, k, h, ison, pos0 = com.posG[igene], pos1 = com.posG[igene + 1];
   double t;

   for (i = 0; i < nodes[inode].nson; i++)
      if (nodes[nodes[inode].sons[i]].nson > 0 && !com.oldconP[nodes[inode].sons[i]])
         ConditionalPNode(nodes[inode].sons[i], igene, x);
   if (inode < com.ns) {  /* young ancestor */
      for (h = pos0*n; h < pos1*n; h++)
         nodes[inode].conP[h] = 0;
   }
   else
      for (h = pos0*n; h < pos1*n; h++)
         nodes[inode].conP[h] = 1;
#+END_EXAMPLE

A própria implementação de lfun não é thread-safe, em particular a linha `if
(LASTROUND == 2) dfsites[h] = fh;`. Os mesmos problemas existem em =lfundG=
(chamada quando alpha=1).

De qualquer forma não sei até que ponto minha paralelização seria útil visto
que o grão é cada derivada parcial do gradiente e as funções sendo derivadas só
tem duas variáveis.

*** Semana 3

**** Resumo executivo

Perfilei com gprof o codeml com os dados de entrada da Agnis, com
resultados semelhantes aos anteriores.

Paralelizei com OpenMP as duas funções responsáveis pela maior parte
do tempo de execução - ConditionalPNode e PMatUVRoot - e escrevi
testes unitários para garantir a corretude da implementação.

Realizei testes de desempenho no PCAD e o desempenho da aplicação
paralela foi significativamente pior que a execução sequencial
anterior. Estou rodando no "shared" do slurm, sempre recebo a beagle
que é uma máquina fraca com dois CPUs Q1'12 2.0 GHz.

Rodei novamente a aplicação sequencial e dessa vez o desempenho também
foi significativamente pior que na execução original. Comparei os
outputs e foram diferentes. Infelizmente não imprimi o hostname da
execução original, mas acredito que era a beagle também. Se fosse uma
máquina diferente explicaria.

Incrementei o meu script de perfil para imprimir o estado do
repositório, informações da máquina, etc. Fiz checkout para o SHA1 da
implementação sequencial original sem nenhuma alteração minha e rodei
duas vezes o codeml, com outputs diferentes, sugerindo que a aplicação
sequencial é não determinística por algum motivo.

Como próximos passos pretendo discutir os resultados obtidos com Julio
e Agnis, revisar com Julio a implementação paralela, e testar o
desempenho novamente da implementação sequencial vs a paralela, dessa
vez em uma máquina que possa se aproveitar mais do paralelismo, a
combinar com Geyer/Julio.

**** Notas completas

Tentar tornar as funções chamadas por gradientB thread-safe parece uma
causa perdida. Além do mais, gradientB é chamado poucas vezes e apenas
com funções de duas variáveis, então sua paralelização talvez nem seja
tão benéfica. Reverti a paralelização em um novo commit no fork do PAML.

Então, estou focando minha atenção no estudo das funções passadas a
gradientB e em seus callees, que, a julgar pelo callgraph do
kacachegrind, são também as funções passadas a LineSearch2,
responsável pela outra metade do tempo de execução.

Para tais funções, duas chamam atenção: PMatUVRoot, uma multiplicação
matricial, e ConditionalPNode, o caller do seu caller. Isso porque
PMatUVRoot é responsável por 35% do tempo de execução, e os outros 64%
do tempo são passados dentro de ConditionalPNode.

PMatUVRoot é chamado 2009013 vezes, enquanto que seus três laço, para
o dataset de exemplo, resultam em 343000 iterações. Obtive esse valor
da seguinte forma: o callgrind reporta 122549792 chamadas para expm1,
que está na inicialização no laço do meio, ou seja, é chamado n vezes
(do laço externo), n = 122549792 / 2009013 = 70, 70^3 = 343000. Cada
uma dessas iterações realiza duas somas e duas multiplicações,
enquanto que 70**2 = 4900 dessas iterações realizam uma exponenciação,
uma multiplicação, e uma subtração (exmp1). Isto é:

- Laço externo: Sem operações, 70x
- Laço do meio: Exponenciação, 70^2 = 4900x
- Laço interno: Duas somas e duas multiplicações, acessos divers, 70^3 = 343000x

O laço mais exterior não é paralelizável, ao menos não trivialmente,
pois utiliza o valor da matriz calculada na iteração anterior. Os dois
laços interiores são paralelizáveis se realizarmos a exponenciação
todas vezes (colapsando-os), ou se paralelizarmos somente o laço mais
interno. Isto é:

- Alternativa 1: 70x mais exponenciação, 4900 iterações paralelizáveis
- Alternativa 2: Mesmas operações, 70 iterações paralelizáveis

Discutível se vale a pena paralelizar aqui, seja com CUDA ou OpenMP.

[[FILE:img/mat.gif]]

Já ConditionalPNode passa a maior parte do seu tempo executando um
laço de pos0 a pos1, aninhado dois laços sob n, no caso "internal
node". É alguma operação matricial, potencialmente
paralelizável. Explorando o tamanho desse laço para o dataset de
exemplo com um printf (callgrind não deu pistas) temos um laço de
tamanho máximo de 706990 (n = 61, pos1=190, pos0=0). 

[[FILE:img/caller.gif]]

#+BEGIN_EXAMPLE
diff --git a/src/codeml.c b/src/codeml.c
index f5c5961..dd7d052 100644
--- a/src/codeml.c
+++ b/src/codeml.c
@@ -3489,6 +3489,7 @@ int Qcodon2aa(double Qc[], double pic[], double Qaa[], double piaa[])
 
 int ConditionalPNode(int inode, int igene, double x[])
 {
+   static long int _loopmax = 0;
    int n = com.ncode, i, j, k, h, ison, pos0 = com.posG[igene], pos1 = com.posG[igene + 1];
    double t;
 
@@ -3530,6 +3531,10 @@ int ConditionalPNode(int inode, int igene, double x[])
             }
       }
       else {                                            /* internal node */
+         if ((pos1 - pos0) * n * n > _loopmax) {
+           _loopmax = (pos1 - pos0) * n * n;
+           printf("new _loopmax: %ld\n", _loopmax);
+         }
          for (h = pos0; h < pos1; h++)
             for (j = 0; j < n; j++) {
                for (k = 0, t = 0; k < n; k++)
#+END_EXAMPLE

Podemos desenrolar esse laço da seguinte forma:

#+BEGIN_EXAMPLE
for (hj = pos0 * n; hj < pos1 * n; hj++) {
  h = hj / n;
  j = hj % n;
  t = 0;
  for (k = 0; k < n; k++) {
    t += PMat[j * n + k] * nodes[ison].conP[h * n + k];
  }
  nodes[inode].conP[h * n + j] = t;
}
#+END_EXAMPLE

Assim temos apens 61^2 = 3721 iterações paralelizáveis. Podemos
desenrolar mais e paralelizar todas 706990 iterações:

#+BEGIN_EXAMPLE
for (hjk = pos0 * nn; hjk < pos1 * nn; hjk++) {
  int h = hjk / (n * n),
      j = (hjk % (n * n)) / n;
      k = (hjk % (n * n)) % n;
  t += PMat[j * n + k] * nodes[ison].conP[h * n + k];
  if (k == n - 1)
    nodes[inode].conP[h * n + j] *= t;
}
#+END_EXAMPLE

Otimizando:

#+BEGIN_EXAMPLE
int nn = n * n;
for (hjk = pos0 * nn; hjk < pos1 * nn; hjk++) {
  int hn = hjk / n,
      h = hn / n,
      jn = (hj % nn),
      j = j / n,
      k = jn % n;
  t += PMat[jn + k] * nodes[ison].conP[hn + k];
  if (k == n - 1)
    nodes[inode].conP[hn + j] *= t;
}
#+END_EXAMPLE

Próximos passos:

1. Escrever testes unitários para essa função
2. Implementar e testar laço desenrolado sequencial
3. Implementar e perfilar paralelização com OpenMP

Talvez seja melhor CUDA pois cada kernel é rápido e há muitos kernels,
mas a validar...

Em paralelo a isso rodei o codeml com os dados da Agnis e callgrind na
beagle, as a execução levou mais de 23h e foi abortada pelo limite de
tempo. Botei para rodar hoje então com o gprof.

Foi paralelizado o ConditionalPNode usando a primeira estratégia de
colapsar apenas os dois laços mais externos. A implementação paralela
é bem simples e me parece correta, mas por algum motivo que ainda não
entendi os resultados ficam levemente diferentes da implementação
sequencial (sem USE_OMP) e os testes unitários falham. Adicionei um
printf para evidenciar:

#+BEGIN_EXAMPLE
./afarah@gentoopc ~/tcc/paml/src/tests $ ./ConditionalPNode 
actual=36.905000; expected=36.905000
actual=56.597750; expected=56.597750
actual=87.121512; expected=87.121512
actual=134.433344; expected=134.433344
actual=207.766684; expected=207.766684
actual=321.433360; expected=321.433360
actual=497.616708; expected=497.616708
actual=770.700897; expected=770.700897
actual=1193.981390; expected=1193.981390
actual=1850.066155; expected=1850.066155
actual=2866.997541; expected=2866.997541
actual=4443.241188; expected=4443.241188
actual=6886.418841; expected=6886.418841
actual=10673.344204; expected=10673.344204
actual=16543.078516; expected=16543.078516
actual=25641.166700; expected=25641.166700
actual=39743.203385; expected=39743.203385
actual=61601.360246; expected=61601.360246
actual=95481.503382; expected=95481.503382
actual=147995.725241; expected=147995.725241
actual=229392.769124; expected=229392.769124
actual=355558.187143; expected=355558.187143
actual=551114.585071; expected=551114.585071
actual=854227.001860; expected=854227.001860
actual=1324051.247883; expected=1324051.247883
actual=2052278.829219; expected=2052278.829219
actual=3181031.580290; expected=3181031.580290
actual=4930598.344449; expected=4930598.344449
actual=7642426.828896; expected=7642426.828896
actual=11845760.979789; expected=11845760.979789
actual=18360928.913673; expected=18360928.913673
actual=28459439.211193; expected=28459439.211193
actual=44112130.172349; expected=44112130.172349
actual=68373801.162141; expected=68373801.162141
actual=105979391.196318; expected=105979391.196318
actual=164268055.749293; expected=164268055.749293
actual=254615485.806405; expected=254615485.806405
actual=394654002.394927; expected=394654002.394927
actual=611713703.107136; expected=611713703.107135
actual=948156239.211061; expected=948156239.211060
ConditionalPNode: ConditionalPNode.c:65: test_ConditionalPNode_InternalNode: Assertion `double_equal(node_actual.conP[h*N + j], node_expected.conP[h*N + j], Small_Diff)' failed.
Aborted
#+END_EXAMPLE

Não paralelo:

#+BEGIN_EXAMPLE
afarah@gentoopc ~/tcc/paml/src/tests $ head -n 50 err
actual=36.905000; expected=36.905000
actual=56.597750; expected=56.597750
actual=87.121512; expected=87.121512
actual=134.433344; expected=134.433344
actual=207.766684; expected=207.766684
actual=321.433360; expected=321.433360
actual=497.616708; expected=497.616708
actual=770.700897; expected=770.700897
actual=1193.981390; expected=1193.981390
actual=1850.066155; expected=1850.066155
actual=2866.997541; expected=2866.997541
actual=4443.241188; expected=4443.241188
actual=6886.418841; expected=6886.418841
actual=10673.344204; expected=10673.344204
actual=16543.078516; expected=16543.078516
actual=25641.166700; expected=25641.166700
actual=39743.203385; expected=39743.203385
actual=61601.360246; expected=61601.360246
actual=95481.503382; expected=95481.503382
actual=147995.725241; expected=147995.725241
actual=229392.769124; expected=229392.769124
actual=355558.187143; expected=355558.187143
actual=551114.585071; expected=551114.585071
actual=854227.001860; expected=854227.001860
actual=1324051.247883; expected=1324051.247883
actual=2052278.829219; expected=2052278.829219
actual=3181031.580290; expected=3181031.580290
actual=4930598.344449; expected=4930598.344449
actual=7642426.828896; expected=7642426.828896
actual=11845760.979789; expected=11845760.979789
actual=18360928.913673; expected=18360928.913673
actual=28459439.211193; expected=28459439.211193
actual=44112130.172349; expected=44112130.172349
actual=68373801.162141; expected=68373801.162141
actual=105979391.196318; expected=105979391.196318
actual=164268055.749293; expected=164268055.749293
actual=254615485.806405; expected=254615485.806405
actual=394654002.394927; expected=394654002.394927
actual=611713703.107135; expected=611713703.107135
actual=948156239.211060; expected=948156239.211060
#+END_EXAMPLE

Após muito debug, descobri que a origem das diferenças é a propagação
de erro de ponto flutuante. Esse problema não é em minha
paralelização, ele está presente na implementação original. O que
ocorre é que a cláusula de redução do OpenMP cria uma cópia privada a
cada threa do acumulador original, alterando as operações que são
realizadas, apesar do resultado final ser logicamente o mesmo. Dessa
forma os erros de arredondamento são diferentes entre a implementação
sequencial e paralela, e a propagação de um erro diferente leva a um
resultado final diferente. Exemplo:

#+BEGIN_EXAMPLE
Init: t = 0

Thread 0: k = 0,1
Thread 1: k = 2,3

Thread 0:
t = 0 + 0.5 * 1.1
t = 0.55 + 0.5 * 1.1
t = 1.1

Thread 1:
t = 0 + 0.5 * 1.1
t = 0.55 + 0.5 * 1.1
t = 1.1

Reduction:
t = 1.1 + 1.1 = 2.2

----

Seq:

t = 0 + 0.5 * 1.1
t = 0.55 + 0.5 * 1.1
t = 1.1 + 0.5 * 1.1
t = 1.6500000000000001 + 0.5 * 1.1
t = 2.2000000000000001
#+END_EXAMPLE

A pista que me levou a essa conclusão é que as diferenças eram apenas
várias casas após a vírgula e só se manifestavam quando eu testava com
um número muito alto de iterações e com ison == inode, o que fazia com
que t fosse grande e o valor das matrizes pequeno, clássico caso que
gera erro de arredondamento em operações com ponto flutuante.

Acredito que não seja motivo de preocupação no que tange a
paralelização do software visto que o problema já está presenta na
implementação sequencial, mas talvez seja relevante estudar o impacto
disso no resultado final da aplicação na própria implementação
sequencial, em um outro trabalho.

Por fim, ressalto que observei o erro apenas com dados arbitrários em
meus testes, não analisei se há problemas relacionados a ponto
flutuante com os dados reais como entrada.

O perfil do codeml com gprof com os dados de entrada da Agnis mostram
que as funções com maior tempo de execução são justamente aquelas que
estou paralelizando:

#+BEGIN_EXAMPLE
afarah@gentoopc ~/tcc/alef/profiling/agnis_GJB3_gprof_20_07_21_181815 $ gprof codeml gmon.out 
Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  Ks/call  Ks/call  name    
 56.33   3673.63  3673.63   465133     0.00     0.00  ConditionalPNode
 37.05   6089.65  2416.03 41861970     0.00     0.00  PMatUVRoot
#+END_EXAMPLE

Um aspecto que não explorei ainda é se há um componente grande de IO,
dado que no PCAD estou rodando no NFS e não no SCRATCH da máquina. Vou
fazer um setup no SCRATCH no futuro próximo para eliminar essa
hipótese.

Vou perfilar agora o tempo total da aplicação com as seguintes estratégias:

1. Sequencial
2. ConditionalPNode paralelizado no laço interno
3. ConditionalPNode paralelizado no laço externo (a desenvolver)
4. PMatUVRoot paralelizado (a desenvolver)

A aplicação com ConditionalPNode paralelo está levando mais do que o
dobro do tempo, a execução foi abortada pelo slurm ao atingir 10h
(dobro do tempo da sequencial). Comparando o output parcial da
aplicação paralela com a sequencial, os resultados estão
diferentes. Uma possível causa é a questão da propagação do erro de
ponto flutuante supracitada. Se a implementação paralela está
aumentando o número de erros catastróficos isso pode alterar o
resultado final. Uma possível solução a explorar é o algoritmo de
Kahan para soma de ponto flutuante visando redução do erro. Uma rápida
busca online indica que pode ser paralelizado.

Output parcial da execução sequencial:

#+BEGIN_EXAMPLE
Bounds (np=93):
   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000100   0.000010   0.000001
  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000 999.000000   0.999990   1.000000
Qfactor_NS = 12.285089

np =    93
lnL0 = -6290.590227

Iterating by ming2
Initial: fx=  6290.590227
x=  0.09072  0.08418  0.01039  0.09082  0.02841  0.08756  0.07494  0.03013  0.05162  0.04067  0.04597  0.03345  0.05665  0.08144  0.07450  0.07960  0.10018  0.10284  0.08212  0.03244  0.04908  0.07749  0.05690  0.04223  0.08911  0.02912  0.01359  0.01485  0.02224  0.03672  0.03540  0.07238  0.05713  0.03231  0.08946  0.10331  0.07271  0.02837  0.08331  0.07611  0.10923  0.08568  0.10434  0.06423  0.01677  0.10779  0.05964  0.10630  0.06570  0.02272  0.10830  0.09979  0.09880  0.08815  0.05337  0.10153  0.07990  0.03075  0.03565  0.08372  0.06842  0.10584  0.04658  0.06866  0.02481  0.03816  0.05232  0.04077  0.02638  0.07968  0.09626  0.10925  0.04827  0.09553  0.02213  0.06993  0.03924  0.06383  0.03491  0.08962  0.09700  0.05041  0.09173  0.01147  0.02272  0.09447  0.08988  0.05477  0.10942  0.01586  0.30000  0.83720  0.33817

  1 h-m-p  0.0000 0.0001 3519.6619 ++     5656.072634  m 0.0001    98 | 1/93
  2 h-m-p  0.0000 0.0000 2710.3408 ++     5625.270033  m 0.0000   194 | 2/93
  3 h-m-p  0.0000 0.0000 30880.9610 ++     5549.982515  m 0.0000   290 | 2/93
  4 h-m-p  0.0000 0.0000 6087.3636 ++     5409.331121  m 0.0000   386 | 3/93
  5 h-m-p  0.0000 0.0000 1826.2723 ++     5351.095448  m 0.0000   482 | 3/93
  6 h-m-p  0.0000 0.0000 2151.4781 +YYYC  5345.938568  3 0.0000   582 | 3/93
  7 h-m-p  0.0000 0.0000 1550.8804 ++     5343.834441  m 0.0000   678 | 4/93
  8 h-m-p  0.0000 0.0000 1520.9943 +YYCYCCC  5330.001649  6 0.0000   784 | 4/93
  9 h-m-p  0.0000 0.0000 3297.1468 +CYYCCC  5315.219769  5 0.0000   889 | 4/93
 10 h-m-p  0.0000 0.0000 7943.2582 ++     5308.866562  m 0.0000   985 | 5/93
 11 h-m-p  0.0000 0.0000 7857.4884 ++     5302.113901  m 0.0000  1081 | 6/93
 12 h-m-p  0.0000 0.0000 3187.5677 ++     5282.510677  m 0.0000  1177 | 7/93
 13 h-m-p  0.0000 0.0000 800.8952 ++     5281.108941  m 0.0000  1273 | 8/93
 14 h-m-p  0.0000 0.0000 545.2480 ++     5279.927959  m 0.0000  1369 | 9/93
 15 h-m-p  0.0000 0.0000 480.1410 ++     5276.041669  m 0.0000  1465 | 10/93
 16 h-m-p  0.0000 0.0000 840.7983 ++     5272.440170  m 0.0000  1561 | 11/93
#+END_EXAMPLE

Output parcial da execução paralela:

#+BEGIN_EXAMPLE
Bounds (np=93):
   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000100   0.000010   0.000001
  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000 999.000000   0.999990   1.000000
Qfactor_NS = 12.144785

np =    93
lnL0 = -6286.776183

Iterating by ming2
Initial: fx=  6286.776183
x=  0.06035  0.04179  0.07858  0.09459  0.10431  0.04290  0.06293  0.09910  0.09405  0.06286  0.02682  0.06364  0.05740  0.02343  0.01451  0.01398  0.06711  0.05110  0.07739  0.03355  0.04966  0.03858  0.04216  0.02427  0.01096  0.10457  0.01376  0.04929  0.03324  0.06290  0.05512  0.10617  0.07321  0.08678  0.06095  0.05381  0.06582  0.02926  0.01774  0.09162  0.01357  0.03581  0.01728  0.06442  0.01590  0.05986  0.06565  0.04147  0.06845  0.06732  0.10507  0.09293  0.03680  0.09105  0.04076  0.06253  0.08440  0.07114  0.03989  0.10947  0.10945  0.09191  0.04497  0.06831  0.02024  0.10176  0.01869  0.05013  0.05391  0.07652  0.01259  0.08346  0.01797  0.06249  0.02660  0.06835  0.10965  0.01001  0.10162  0.09208  0.04240  0.08341  0.06256  0.02998  0.08456  0.10842  0.10365  0.02966  0.08957  0.09299  0.30000  0.79448  0.31112

  1 h-m-p  0.0000 0.0001 3885.8372 ++     5793.033196  m 0.0001    98 | 1/93
  2 h-m-p  0.0000 0.0000 2662.1485 ++     5672.889985  m 0.0000   194 | 2/93
  3 h-m-p  0.0000 0.0001 3919.3314 +
    0.056618    0.099948    0.050574    0.075448    0.065415    0.006914    0.072660    0.074720    0.092124    0.034438    0.029251    0.032628    0.029038    0.044777    0.000004    0.004579    0.021114    0.041404    0.035605    0.028542    0.025763    0.030070    0.067436    0.045226    0.091034    0.126164    0.111483    0.079464    0.036372    0.026665    0.028260    0.065816    0.045828    0.102591    0.103195    0.050080    0.072178    0.124551    0.085463    0.104570    0.061385    0.066672    0.059426    0.041428    0.084706    0.061267    0.039506    0.056616    0.068535    0.047787    0.070110    0.084635    0.043997    0.071349    0.014430    0.018399    0.045921    0.039840    0.038045    0.065976    0.072631    0.052540    0.001661    0.024653    0.000004    0.058010    0.057861    0.040223    0.065034    0.049864    0.004999    0.067909    0.022347    0.044998    0.023883    0.064066    0.073994    0.032601    0.081026    0.071210    0.024028    0.058567    0.054941    0.035118    0.041305    0.087314    0.060741    0.015624    0.058924    0.070214    0.458603    0.806044    0.000001

fx_r: h = 63  r = 1 fhK = -8.10101e-06 YYYYCYCCCC  5417.091462  9 0.0001   304 | 2/93
  4 h-m-p  0.0000 0.0000 985.1224 ++     5395.084279  m 0.0000   400 | 3/93
  5 h-m-p  0.0000 0.0000 5181.3853 ++     5368.710274  m 0.0000   496 | 4/93
  6 h-m-p  0.0000 0.0000 1824.6330 +CYYCCCC  5358.884881  6 0.0000   603 | 4/93
  7 h-m-p  0.0000 0.0000 9763.2008 ++     5354.459472  m 0.0000   699 | 5/93
  8 h-m-p  0.0000 0.0000 171680.9178 ++     5352.259145  m 0.0000   795 | 6/93
  9 h-m-p  0.0000 0.0000 1466.7161 ++     5343.973917  m 0.0000   891 | 7/93
 10 h-m-p  0.0000 0.0000 1380.8961 ++     5320.637451  m 0.0000   987 | 8/93
 11 h-m-p  0.0000 0.0000 2566.5588 ++     5309.281526  m 0.0000  1083 | 9/93
 12 h-m-p  0.0000 0.0000 3723.5023 ++     5303.867686  m 0.0000  1179 | 10/93
 13 h-m-p  0.0000 0.0000 1947.8847 ++     5302.281072  m 0.0000  1275 | 11/93
 14 h-m-p  0.0000 0.0000 745.6280 ++     5299.450888  m 0.0000  1371 | 12/93
 15 h-m-p  0.0000 0.0002 330.9001 ++     5281.209844  m 0.0002  1467 | 12/93
 16 h-m-p  0.0000 0.0000 2160.0437 +YYYYCC  5279.088386  5 0.0000  1570 | 12/93
 17 h-m-p  0.0000 0.0000 2051.5186 +CYYC  5272.938923  3 0.0000  1671 | 12/93
 18 h-m-p  0.0000 0.0000 2009.1279 +CYCCC  5268.921338  4 0.0000  1775 | 12/93
 19 h-m-p  0.0000 0.0000 1165.8630 +YYYCCC  5263.039450  5 0.0000  1879 | 12/93
 20 h-m-p  0.0000 0.0000 923.4610 +YYYC  5258.943865  3 0.0000  1979 | 12/93
 21 h-m-p  0.0000 0.0000 1594.0010 +YCCC  5255.525396  3 0.0000  2081 | 12/93
 22 h-m-p  0.0000 0.0000 2514.1056 +YYCCC  5250.687418  4 0.0000  2184 | 12/93
#+END_EXAMPLE

No meio tempo, rodei novamente a execução paralela com um print para
ver o número de threads e tamanho do chunk sendo usado, pois não tenho
certeza se minha parametrização do slurm está correta.

Por fim, paralelizei o PMatUVRoot colapsando dois laços e escrevi
testes unitários para ele. Também refatorei o Makefile para permitir
compilar com apenas determinados trechso paralelizados.

Assim que terminar de executar a implementação paralela com print no
PCAD botarei para rodar a implementação com apenas o PMatUVRoot
paralelo, visto que a paralelização do CPNode foi infrutífera.

#+BEGIN_EXAMPLE
diff --git a/src/tools.c b/src/tools.c
index 7e9d544..357faec 100644
--- a/src/tools.c
+++ b/src/tools.c
@@ -523,17 +523,34 @@ int PMatUVRoot(double P[], double t, int n, double U[], double V[], double Root[
 {
    /* P(t) = U * exp{Root*t} * V
    */
-   int i, j, k;
+   int i, j, k, ij;
    double exptm1, uexpt, *pP;
+#ifdef USE_OMP_PMATUV
+   int actual_threads = MAX(1, MIN(omp_get_num_procs(), (n * n)));
+   int chunk = MAX(1, (n * n) / actual_threads);
+#endif
 
    NPMatUVRoot++;
-   memset(P, 0, n*n * sizeof(double));
+   memset(P, 0, n * n * sizeof(double));
+
    for (k = 0; k < n; k++) {
-      for (i = 0, pP = P, exptm1 = expm1(t*Root[k]); i < n; i++)
-         for (j = 0, uexpt = U[i*n + k] * exptm1; j < n; j++)
-            *pP++ += uexpt*V[k*n + j];
+      pP = P; 
+      exptm1 = expm1(t * Root[k]);
+      uexpt = NAN;
+#ifdef USE_OMP_PMATUV
+      #pragma omp parallel for default(shared) private(i, j, ij) firstprivate(uexpt) schedule(static, chunk) num_threads(actual_threads)
+#endif
+      for (ij = 0; ij < n * n; ij++) {
+         i = ij / n;
+         j = ij % n;
+         if (isnan(uexpt) || j == 0)
+           uexpt = U[i*n + k] * exptm1;
+         pP[i*n + j] += uexpt * V[k*n + j];
+      }
    }
-   for (i = 0; i < n; i++)  P[i*n+i] ++;
+
+   for (i = 0; i < n; i++)  
+     P[i*n + i]++;
 
 #if (DEBUG>=5)
    if (testTransP(P, n)) {
#+END_EXAMPLE

Pretendo no futuro alterar o script de profiling parametrizando as
regiões paralelas para não precisar ficar alterando manualmente o
Makefile e a fim de tornar os experimentos mais reprodutíveis.

Já pensando no caso das paralelizações "microscópicas" não
funcionarem, uma abordagem alternativa é buscar uma paralelização mais
"macroscópica", estudando o que o código faz hoje em sequência que
poderia ser feito em paralelo, semelhante ao que foi feito no trabalho
relacionado em que é rodada a instância inteira do codeml em paralelo,
mas buscando um grão um pouco mais fino - p.e. se há vários modelos
sendo comparados em uma execução do codeml, ver se não seria possível
rodar esses modelos em paralelo. Preciso ver em mais detalhes o
trabalho mencionado para ver se não fizeram isso (também).

Resultados da paralelização da PMatUVRoot apresentaram exatamente o
mesmo problema da CPNode, estourando o tempo limite (levando pelo
menos 2x o tempo da execução sequencial) e com resultados diferentes:

#+BEGIN_EXAMPLE
Bounds (np=93):
   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004
   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000100   0.000010   0.000001
  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000 999.000000   0.999990   1.000000
Qfactor_NS = 12.285089

np =    93
lnL0 = -6290.590227
#+END_EXAMPLE

#+BEGIN_EXAMPLE
Bounds (np=93):
   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004
   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004
   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004
   0.000004   0.000004   0.000004   0.000100   0.000010   0.000001
  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000
  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000
  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000
  50.000000  50.000000  50.000000 999.000000   0.999990   1.000000
Qfactor_NS = 14.846743

np =    93
lnL0 = -5935.288424
#+END_EXAMPLE

Eu estava usando somente o PMatUVRoot paralelo:

#+BEGIN_EXAMPLE
afarah@gppd-hpc:~/tcc/alef/profiling$ head tcc_geyer_tt_par_uvroot_agnis_440141.out 
/home/users/afarah/tcc/alef/profiling/../paml/src
/home/users/afarah/tcc/alef/profiling/../data/agnis_GJB3

Starting in 5s from /home/users/afarah/tcc/alef/profiling/agnis_GJB3_total_time_24_07_21_194957

rm -f *.o baseml codeml basemlg mcmctree pamp evolver yn00 chi2 infinitesites
cc  -O3 -Wall -Wno-unused-result  -DUSE_OMP -fopenmp -DUSE_OMP_PMATUV -c codeml.c
cc  -O3 -Wall -Wno-unused-result  -DUSE_OMP -fopenmp -DUSE_OMP_PMATUV -c tools.c
cc  -O3 -Wall -Wno-unused-result  -DUSE_OMP -fopenmp -DUSE_OMP_PMATUV -o codeml codeml.o tools.o -lm -lgomp
Running total_time from /home/users/afarah/tcc/alef/profiling/agnis_GJB3_total_time_24_07_21_194957...
#+END_EXAMPLE

#+BEGIN_EXAMPLE
afarah@gppd-hpc:~/tcc/alef/paml/src$ grep -re USE_OMP -A2
tests/Makefile:# USE_OMP - Use OpenMP (at all)
tests/Makefile:# USE_OMP_CPNODE - Use OpenMP on ConditionalPNode
tests/Makefile:# USE_OMP_PMATUV - Use OpenMP on PMatUVRoot
tests/Makefile-#
tests/Makefile-override CFLAGS += $(DBG) -Wall -Wno-unused-result 
tests/Makefile:override CFLAGS += -DUSE_OMP -fopenmp
tests/Makefile:#override CFLAGS += -DUSE_OMP_CPNODE
tests/Makefile:#override CFLAGS += -DUSE_OMP_PMATUV
tests/Makefile-LIBS = -lm -lgomp
tests/Makefile-
--
Makefile:# USE_OMP - Use OpenMP (at all)
Makefile:# USE_OMP_CPNODE - Use OpenMP on ConditionalPNode
Makefile:# USE_OMP_PMATUV - Use OpenMP on PMatUVRoot
Makefile-#
Makefile-override CFLAGS += -O3 -Wall -Wno-unused-result 
Makefile:override CFLAGS += -DUSE_OMP -fopenmp
Makefile:#override CFLAGS += -DUSE_OMP_CPNODE
Makefile:override CFLAGS += -DUSE_OMP_PMATUV
Makefile-LIBS = -lm -lgomp
Makefile-
--
codeml.c:#ifdef USE_OMP
codeml.c-#include "omp.h"
codeml.c-#endif
--
codeml.c:#ifdef USE_OMP_CPNODE
codeml.c-  int actual_threads = MAX(1, MIN(omp_get_num_procs(), n));
codeml.c-  int chunk = MAX(1, n / actual_threads);
--
codeml.c:#ifdef USE_OMP_CPNODE
codeml.c-    #pragma omp parallel for schedule(static, chunk) num_threads(actual_threads) default(shared) private(k) reduction(+:t)
codeml.c-#endif
--
tools.c:#ifdef USE_OMP
tools.c-#include <omp.h>
tools.c-#endif
--
tools.c:#ifdef USE_OMP_PMATUV
tools.c-   int actual_threads = MAX(1, MIN(omp_get_num_procs(), (n * n)));
tools.c-   int chunk = MAX(1, (n * n) / actual_threads);
--
tools.c:#ifdef USE_OMP_PMATUV
tools.c-      #pragma omp parallel for default(shared) private(i, j, ij) firstprivate(uexpt) schedule(static, chunk) num_threads(actual_threads)
tools.c-#endif
#+END_EXAMPLE

Uma coisa que percebi é que a beagle tem somente duas threads
disponíveis quando rodo como shared, talvez isso esteja impactando,
mas não deveria impactar tanto...

Eu estranhei a implementação sequencial estar tão mais rápida então
rodei de novo e dessa vez estourou o tempo! Achei curioso e,
comparando os resultados de rodadas sequenciais anteriores, os
resultados impressos são diferentes. Achei que o problema fosse em
minhas alterações para paralelizar o código então retornei a um SHA1
anterior e botei em meu script de perfilamento para imprimir o status
do repositório e seu SHA1, limpando-o previamente com stash e clean. A
implementação sequencial original realmente parece não determinística
por algum motivo:

#+BEGIN_EXAMPLE
afarah@beagle:~/tcc/alef/profiling$ ./run_profile.sh total_time agnis_GJB3 SEQ
/home/users/afarah/tcc/alef/profiling/../paml/src
/home/users/afarah/tcc/alef/profiling/../data/agnis_GJB3

Starting in 5s from /home/users/afarah/tcc/alef/profiling/agnis_GJB3_total_time_27_07_21_075927

No local changes to save
Removing codeml
Removing codeml.o
Removing tools.o
881a9f1ccafd0ffcf56885aff78bbf682d61e3b6 (HEAD, tag: v4.10.0) remove compiler warning messages, #4
rm *.o baseml codeml basemlg mcmctree pamp evolver yn00 chi2
rm: cannot remove '*.o': No such file or directory
rm: cannot remove 'baseml': No such file or directory
rm: cannot remove 'codeml': No such file or directory
rm: cannot remove 'basemlg': No such file or directory
rm: cannot remove 'mcmctree': No such file or directory
rm: cannot remove 'pamp': No such file or directory
rm: cannot remove 'evolver': No such file or directory
rm: cannot remove 'yn00': No such file or directory
rm: cannot remove 'chi2': No such file or directory
make: [Makefile:47: clean] Error 1 (ignored)
cc   -c codeml.c
cc   -c tools.c
cc   -o codeml codeml.o tools.o -lm 
Running total_time from /home/users/afarah/tcc/alef/profiling/agnis_GJB3_total_time_27_07_21_075927...

 15         verbose | verbose                0.00
  7         runmode | runmode                0.00
  4         seqtype | seqtype                1.00
 13       CodonFreq | CodonFreq              2.00
  9           clock | clock                  0.00
 18          aaDist | aaDist                 0.00
 16           model | model                  0.00
 20         NSsites | NSsites                1.00
 22           icode | icode                  0.00
 23           Mgene | Mgene                  0.00
 24       fix_kappa | fix_kappa              0.00
 25           kappa | kappa                  0.30
 26       fix_omega | fix_omega              0.00
 27           omega | omega                  1.30
 30          Malpha | Malpha                 0.00
 31           ncatG | ncatG                 10.00
 11           getSE | getSE                  0.00
 12    RateAncestor | RateAncestor           0.00
 36      Small_Diff | Small_Diff             0.00
  6       cleandata | cleandata              0.00
 37     fix_blength | fix_blength            0.00
CODONML in paml version 4.10.0, September 2020

----------------------------------------------
Phe F TTT | Ser S TCT | Tyr Y TAT | Cys C TGT
      TTC |       TCC |       TAC |       TGC
Leu L TTA |       TCA | *** * TAA | *** * TGA
      TTG |       TCG |       TAG | Trp W TGG
----------------------------------------------
Leu L CTT | Pro P CCT | His H CAT | Arg R CGT
      CTC |       CCC |       CAC |       CGC
      CTA |       CCA | Gln Q CAA |       CGA
      CTG |       CCG |       CAG |       CGG
----------------------------------------------
Ile I ATT | Thr T ACT | Asn N AAT | Ser S AGT
      ATC |       ACC |       AAC |       AGC
      ATA |       ACA | Lys K AAA | Arg R AGA
Met M ATG |       ACG |       AAG |       AGG
----------------------------------------------
Val V GTT | Ala A GCT | Asp D GAT | Gly G GGT
      GTC |       GCC |       GAC |       GGC
      GTA |       GCA | Glu E GAA |       GGA
      GTG |       GCG |       GAG |       GGG
----------------------------------------------
Nice code, uuh?
NSsites batch run (ncatG as in YNGP2000):   1  2  7  8


Ambiguity character definition table:

T (1): T 
C (1): C 
A (1): A 
G (1): G 
U (1): T 
Y (2): T C 
R (2): A G 
M (2): C A 
K (2): T G 
S (2): C G 
W (2): T A 
H (3): T C A 
B (3): T C G 
V (3): C A G 
D (3): T A G 
- (4): T C A G 
N (4): T C A G 
? (4): T C A G 
ns = 46         ls = 810
Reading sequences, sequential format..
Reading seq # 1: Homo_sapiens       
Reading seq # 2: Pan_paniscus       
Reading seq # 3: Pan_troglodytes       
Reading seq # 4: Gorilla_gorilla       
Reading seq # 5: Pongo_abelii       
Reading seq # 6: Nomascus_leucogenys       
Reading seq # 7: Hylobates_moloch       
Reading seq # 8: Chlorocebus_sabaeus
Reading seq # 9: Macaca_mulatta       
Reading seq #10: Macaca_fascicularis       
Reading seq #11: Theropithecus_gelada       
Reading seq #12: Macaca_nemestrina       
Reading seq #13: Mandrillus_leucophaeus       
Reading seq #14: Papio_anubis       
Reading seq #15: Cercocebus_atys       
Reading seq #16: Colobus_angolensis       
Reading seq #17: Trachypithecus_francoisi       
Reading seq #18: Rhinopithecus_bieti       
Reading seq #19: Sapajus_apella       
Reading seq #20: Rhinopithecus_roxellana       
Reading seq #21: Cebus_capucinus       
Reading seq #22: Piliocolobus_tephrosceles       
Reading seq #23: Saimiri_boliviensis       
Reading seq #24: Aotus_nancymaae       
Reading seq #25: Callithrix_jacchus       
Reading seq #26: Microcebus_murinus       
Reading seq #27: Propithecus_coquereli       
Reading seq #28: Balaenoptera_musculus       
Reading seq #29: Tursiops_truncatus       
Reading seq #30: Orcinus_orca       
Reading seq #31: Lagenorhynchus_obliquidens       
Reading seq #32: Globicephala_melas       
Reading seq #33: Phocoena_sinus       
Reading seq #34: Monodon_monoceros       
Reading seq #35: Delphinapterus_leucas       
Reading seq #36: Balaenoptera_acutorostrata       
Reading seq #37: Physeter_catodon       
Reading seq #38: Rhinolophus_ferrumequinum       
Reading seq #39: Pteropus_vampyrus       
Reading seq #40: Pteropus_alecto       
Reading seq #41: Pteropus_giganteus       
Reading seq #42: Lipotes_vexillifer       
Reading seq #43: Hipposideros_armiger       
Reading seq #44: Otolemur_garnettii       
Reading seq #45: Molossus_molossus       
Reading seq #46: Rousettus_aegyptiacus       

Sequences read..
Counting site patterns..  0:00
Compressing,    210 patterns at    270 /    270 sites (100.0%),  0:00
Collecting fpatt[] & pose[],    210 patterns at    270 /    270 sites (100.0%),  0:00
Counting codons..

     8280 bytes for distance
   204960 bytes for conP
    18480 bytes for fhK
  5000000 bytes for space


Model 1: NearlyNeutral

TREE #  1

This is a rooted tree, without clock.  Check.

  4611600 bytes for conP, adjusted

2 node(s) used for scaling (Yang 2000 J Mol Evol 51:423-432):
 48 73
    0.104372    0.090371    0.084294    0.030779    0.077702    0.049033    0.079213    0.081265    0.100111    0.059066    0.077885    0.089631    0.047407    0.102517    0.096285    0.019422    0.010059    0.014968    0.070213    0.062974    0.068256    0.097739    0.061178    0.107273    0.086020    0.108897    0.093032    0.080977    0.016546    0.031510    0.099065    0.018514    0.085963    0.092592    0.034221    0.052221    0.097694    0.081155    0.082158    0.018437    0.074618    0.088834    0.061802    0.038505    0.031200    0.071499    0.013110    0.010610    0.042805    0.105308    0.016717    0.023397    0.054352    0.085618    0.077157    0.077304    0.045524    0.092223    0.074348    0.074543    0.044694    0.019322    0.063022    0.013677    0.058788    0.043679    0.074796    0.099718    0.061232    0.079402    0.052562    0.055698    0.055212    0.042782    0.021898    0.096634    0.104397    0.025623    0.079165    0.101834    0.098346    0.050514    0.051005    0.096490    0.094755    0.056463    0.054900    0.028472    0.055762    0.038348    0.300000    0.722015    0.556418

ntime & nrate & np:    90     2    93

Bounds (np=93):
   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000100   0.000010   0.000001
  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000 999.000000   0.999990   1.000000
Qfactor_NS = 8.786251

np =    93
lnL0 = -6351.476469

Iterating by ming2
Initial: fx=  6351.476469
x=  0.10437  0.09037  0.08429  0.03078  0.07770  0.04903  0.07921  0.08126  0.10011  0.05907  0.07789  0.08963  0.04741  0.10252  0.09628  0.01942  0.01006  0.01497  0.07021  0.06297  0.06826  0.09774  0.06118  0.10727  0.08602  0.10890  0.09303  0.08098  0.01655  0.03151  0.09906  0.01851  0.08596  0.09259  0.03422  0.05222  0.09769  0.08115  0.08216  0.01844  0.07462  0.08883  0.06180  0.03851  0.03120  0.07150  0.01311  0.01061  0.04280  0.10531  0.01672  0.02340  0.05435  0.08562  0.07716  0.07730  0.04552  0.09222  0.07435  0.07454  0.04469  0.01932  0.06302  0.01368  0.05879  0.04368  0.07480  0.09972  0.06123  0.07940  0.05256  0.05570  0.05521  0.04278  0.02190  0.09663  0.10440  0.02562  0.07917  0.10183  0.09835  0.05051  0.05101  0.09649  0.09476  0.05646  0.05490  0.02847  0.05576  0.03835  0.30000  0.72202  0.55642

^Cafarah@beagle:~/tcc/alef/profiling$ 
#+END_EXAMPLE

Rodando novamente a mesma coisa:

#+BEGIN_EXAMPLE
Cafarah@beagle:~/tcc/alef/profiling$ ./run_profile.sh total_time agnis_GJB3 SEQ
/home/users/afarah/tcc/alef/profiling/../paml/src
/home/users/afarah/tcc/alef/profiling/../data/agnis_GJB3

Starting in 5s from /home/users/afarah/tcc/alef/profiling/agnis_GJB3_total_time_27_07_21_080138

No local changes to save
Removing codeml
Removing codeml.o
Removing tools.o
881a9f1ccafd0ffcf56885aff78bbf682d61e3b6 (HEAD, tag: v4.10.0) remove compiler warning messages, #4
rm *.o baseml codeml basemlg mcmctree pamp evolver yn00 chi2
rm: cannot remove '*.o': No such file or directory
rm: cannot remove 'baseml': No such file or directory
rm: cannot remove 'codeml': No such file or directory
rm: cannot remove 'basemlg': No such file or directory
rm: cannot remove 'mcmctree': No such file or directory
rm: cannot remove 'pamp': No such file or directory
rm: cannot remove 'evolver': No such file or directory
rm: cannot remove 'yn00': No such file or directory
rm: cannot remove 'chi2': No such file or directory
make: [Makefile:47: clean] Error 1 (ignored)
cc   -c codeml.c
cc   -c tools.c
cc   -o codeml codeml.o tools.o -lm 
Running total_time from /home/users/afarah/tcc/alef/profiling/agnis_GJB3_total_time_27_07_21_080138...

 15         verbose | verbose                0.00
  7         runmode | runmode                0.00
  4         seqtype | seqtype                1.00
 13       CodonFreq | CodonFreq              2.00
  9           clock | clock                  0.00
 18          aaDist | aaDist                 0.00
 16           model | model                  0.00
 20         NSsites | NSsites                1.00
 22           icode | icode                  0.00
 23           Mgene | Mgene                  0.00
 24       fix_kappa | fix_kappa              0.00
 25           kappa | kappa                  0.30
 26       fix_omega | fix_omega              0.00
 27           omega | omega                  1.30
 30          Malpha | Malpha                 0.00
 31           ncatG | ncatG                 10.00
 11           getSE | getSE                  0.00
 12    RateAncestor | RateAncestor           0.00
 36      Small_Diff | Small_Diff             0.00
  6       cleandata | cleandata              0.00
 37     fix_blength | fix_blength            0.00
CODONML in paml version 4.10.0, September 2020

----------------------------------------------
Phe F TTT | Ser S TCT | Tyr Y TAT | Cys C TGT
      TTC |       TCC |       TAC |       TGC
Leu L TTA |       TCA | *** * TAA | *** * TGA
      TTG |       TCG |       TAG | Trp W TGG
----------------------------------------------
Leu L CTT | Pro P CCT | His H CAT | Arg R CGT
      CTC |       CCC |       CAC |       CGC
      CTA |       CCA | Gln Q CAA |       CGA
      CTG |       CCG |       CAG |       CGG
----------------------------------------------
Ile I ATT | Thr T ACT | Asn N AAT | Ser S AGT
      ATC |       ACC |       AAC |       AGC
      ATA |       ACA | Lys K AAA | Arg R AGA
Met M ATG |       ACG |       AAG |       AGG
----------------------------------------------
Val V GTT | Ala A GCT | Asp D GAT | Gly G GGT
      GTC |       GCC |       GAC |       GGC
      GTA |       GCA | Glu E GAA |       GGA
      GTG |       GCG |       GAG |       GGG
----------------------------------------------
Nice code, uuh?
NSsites batch run (ncatG as in YNGP2000):   1  2  7  8
Ambiguity character definition table:

T (1): T 
C (1): C 
A (1): A 
G (1): G 
U (1): T 
Y (2): T C 
R (2): A G 
M (2): C A 
K (2): T G 
S (2): C G 
W (2): T A 
H (3): T C A 
B (3): T C G 
V (3): C A G 
D (3): T A G 
- (4): T C A G 
N (4): T C A G 
? (4): T C A G 
ns = 46         ls = 810
Reading sequences, sequential format..
Reading seq # 1: Homo_sapiens       
Reading seq # 2: Pan_paniscus       
Reading seq # 3: Pan_troglodytes       
Reading seq # 4: Gorilla_gorilla       
Reading seq # 5: Pongo_abelii       
Reading seq # 6: Nomascus_leucogenys       
Reading seq # 7: Hylobates_moloch       
Reading seq # 8: Chlorocebus_sabaeus       
Reading seq # 9: Macaca_mulatta       
Reading seq #10: Macaca_fascicularis       
Reading seq #11: Theropithecus_gelada       
Reading seq #12: Macaca_nemestrina       
Reading seq #13: Mandrillus_leucophaeus       
Reading seq #14: Papio_anubis       
Reading seq #15: Cercocebus_atys       
Reading seq #16: Colobus_angolensis       
Reading seq #17: Trachypithecus_francoisi       
Reading seq #18: Rhinopithecus_bieti       
Reading seq #19: Sapajus_apella       
Reading seq #20: Rhinopithecus_roxellana       
Reading seq #21: Cebus_capucinus       
Reading seq #22: Piliocolobus_tephrosceles       
Reading seq #23: Saimiri_boliviensis       
Reading seq #24: Aotus_nancymaae       
Reading seq #25: Callithrix_jacchus       
Reading seq #26: Microcebus_murinus       
Reading seq #27: Propithecus_coquereli       
Reading seq #28: Balaenoptera_musculus       
Reading seq #29: Tursiops_truncatus       
Reading seq #30: Orcinus_orca       
Reading seq #31: Lagenorhynchus_obliquidens       
Reading seq #32: Globicephala_melas       
Reading seq #33: Phocoena_sinus       
Reading seq #34: Monodon_monoceros       
Reading seq #35: Delphinapterus_leucas       
Reading seq #36: Balaenoptera_acutorostrata       
Reading seq #37: Physeter_catodon       
Reading seq #38: Rhinolophus_ferrumequinum       
Reading seq #39: Pteropus_vampyrus       
Reading seq #40: Pteropus_alecto       
Reading seq #41: Pteropus_giganteus       
Reading seq #42: Lipotes_vexillifer       
Reading seq #43: Hipposideros_armiger       
Reading seq #44: Otolemur_garnettii       
Reading seq #45: Molossus_molossus       
Reading seq #46: Rousettus_aegyptiacus       

Sequences read..
Counting site patterns..  0:00
Compressing,    210 patterns at    270 /    270 sites (100.0%),  0:00
Collecting fpatt[] & pose[],    210 patterns at    270 /    270 sites (100.0%),  0:00
Counting codons..
     8280 bytes for distance
   204960 bytes for conP
    18480 bytes for fhK
  5000000 bytes for space


Model 1: NearlyNeutral

TREE #  1

This is a rooted tree, without clock.  Check.

  4611600 bytes for conP, adjusted

2 node(s) used for scaling (Yang 2000 J Mol Evol 51:423-432):
 48 73

    0.064347    0.022481    0.081054    0.055749    0.043868    0.018697    0.024509    0.032300    0.016991    0.052220    0.015998    0.076943    0.068504    0.093590    0.097533    0.023099    0.034782    0.048958    0.098307    0.088637    0.081492    0.087813    0.098677    0.028357    0.030028    0.035459    0.042095    0.091067    0.099862    0.103669    0.049680    0.092179    0.109002    0.107968    0.067109    0.087781    0.049744    0.094968    0.048522    0.011102    0.031901    0.078202    0.057128    0.107322    0.060704    0.055894    0.037194    0.077657    0.091555    0.059093    0.087111    0.018658    0.078829    0.053623    0.038223    0.017666    0.010895    0.094278    0.019097    0.040356    0.098566    0.104693    0.059944    0.021304    0.059154    0.031346    0.066851    0.043522    0.013307    0.095114    0.070529    0.067897    0.086838    0.038825    0.029264    0.048468    0.084720    0.044243    0.040751    0.044481    0.079430    0.066927    0.092502    0.015155    0.030843    0.012395    0.055516    0.058106    0.029853    0.052039    0.300000    0.863608    0.186799

ntime & nrate & np:    90     2    93

Bounds (np=93):
   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000004   0.000100   0.000010   0.000001
  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000  50.000000 999.000000   0.999990   1.000000
Qfactor_NS = 16.432756

np =    93
lnL0 = -6065.117504

Iterating by ming2
Initial: fx=  6065.117504
x=  0.06435  0.02248  0.08105  0.05575  0.04387  0.01870  0.02451  0.03230  0.01699  0.05222  0.01600  0.07694  0.06850  0.09359  0.09753  0.02310  0.03478  0.04896  0.09831  0.08864  0.08149  0.08781  0.09868  0.02836  0.03003  0.03546  0.04210  0.09107  0.09986  0.10367  0.04968  0.09218  0.10900  0.10797  0.06711  0.08778  0.04974  0.09497  0.04852  0.01110  0.03190  0.07820  0.05713  0.10732  0.06070  0.05589  0.03719  0.07766  0.09156  0.05909  0.08711  0.01866  0.07883  0.05362  0.03822  0.01767  0.01089  0.09428  0.01910  0.04036  0.09857  0.10469  0.05994  0.02130  0.05915  0.03135  0.06685  0.04352  0.01331  0.09511  0.07053  0.06790  0.08684  0.03883  0.02926  0.04847  0.08472  0.04424  0.04075  0.04448  0.07943  0.06693  0.09250  0.01515  0.03084  0.01240  0.05552  0.05811  0.02985  0.05204  0.30000  0.86361  0.18680
^Cafarah@beagle:~/tcc/alef/profiling$ 
#+END_EXAMPLE

*** Semana 4

**** Resumo executivo

Estudei o algoritmo e os métodos numéricos por trás do codeml em mais detalhes,
tanto via análise do código como leitura da literatura.

Em meio a esse estudo identifiquei dois trabalhos em cima do codeml, dos mesmos
autores, em que acredito que os próximos passos desse trabalho devam ser baseados.

O primeiro desses trabalhos é o SlimCodeML, que mantém o mesmo formato de
entrada e saída do codeml, mas substitui a implementação ingênua de métodos
numéricos por aquela do BLAS e LAPACK, além de trazer otimizações e melhorias
organizacionais diversas.

O segundo é o FastCodeML, que mantém o modelo evolutivo original, mas altera
fundamentalmente as estratégias empregadas a fim de remover dependências de
dados, e paraleliza o cálculo com OpenMP e MPI. O código é completamente
reescrito para isso, sendo muito mais organizado. Os arquivos de entrada são os
mesmos, mas os parâmetros não, e o formato de saída é diferente.

Criei uma imagem docker na máquina Thor1 (ubuntu-afarah-fastcodeml) contendo o
codeml original, o SlimCodeML, o FastCodeML, todas libs necessárias para
compilação de todos, bem como um script para perfilar cada um deles.

Em paralelo, identifiquei na literatura uma implementação para GPU do BFGS, o
otimizador usado pelo codeml e seus derivados.

Acredito que os próximos passos desse trabalho devam ser em cima do SlimCodeML
ou do FastCodeML - seria contraprodutivo re-inventarmos a roda trabalhando em
cima do codeml original, cuja base de código é mal organizada e ineficiente.
Minha sugestão para os próximos passos é:

1. Estudar a viabilidade de realizar a análise da Agnis no Slim e Fast codeml
2. Perfilar as aplicações e identificar os gargalos
3. Estudar a viabilidade de uma implementação para GPU das partes menos
   eficientes, seja em cima do FastCodeML ou do SlimCodeML

**** Notas completas

O codeml implementa BFGS em ming3. Encontrei em [3] uma implementação para GPU.

Buscando entender em mais detalhes a implementação do BFGS e demais métodos
envolvidos no CodeML como Markov, encontrei em [4] um trabalho em cima
do CodeML que produz um novo projeto chamado SlimCodeML, que mantém o mesmo
formato de entrada e saída do codeml, mas substitui a implementação ingênua de
métodos numéricos por aquela do BLAS e LAPACK, além de trazer otimizações e
melhorias organizacionais diversas.

Esse trabalho faz tudo que eu havia começado a fazer - substituir laços em
tools.c por memcpy quando possível, substituir implementações ingênus por libs
bem estabelecidas, etc - e muito mais.

Encontrei então um segundo trabalho dos mesmos autores em [5], que produz o
proejto FastCodeML, que mantém o modelo evolutivo original, mas altera
fundamentalmente as estratégias empregadas a fim de remover dependências de
dados, e paraleliza o cálculo com OpenMP e MPI. O código é completamente
reescrito para isso, sendo muito mais organizado. Os arquivos de entrada são os
mesmos, mas os parâmetros não, e o formato de saída é diferente.

Criei uma imagem docker na máquina Thor1 (ubuntu-afarah-fastcodeml) contendo o
codeml original, o SlimCodeML, o FastCodeML, todas libs necessárias para
compilação de todos, bem como um script para perfilar cada um deles. Foi
necessário adaptar o CMakeLists do SlimCodeML e instalar algumas libs somente,
além de aprender o básico de docker.

Acredito que os próximos passos desse trabalho devam ser em cima do SlimCodeML
ou do FastCodeML - seria contraprodutivo re-inventarmos a roda trabalhando em
cima do codeml original, cuja base de código é mal organizada e ineficiente.
Eu jamais conseguiria fazer sozinho em um (ou dois) semestres as otimizações
que múltiplos autores (doutores) fizeram ao longo de vários anos.  Minha
sugestão para os próximos passos desse trabalho então é:

1. Estudar a viabilidade de realizar a análise da Agnis no Slim e Fast codeml
2. Perfilar as aplicações e identificar os gargalos
3. Estudar a viabilidade de uma implementação para GPU das partes menos
   eficientes, seja em cima do FastCodeML ou do SlimCodeML

Para isso, já iniciei na Thor1 uma execução do SlimCodeML com os dados da
Agnis, visto que ele aceita exatamente o mesmo input. Estou estudando como
utilizar o FastCodeML para fazer a mesma análise da Agnis, mas talvez seja
necessário conversarmos para entender melhor cada parâmetro e porventura
conversar com os autores do FastCodeML para entender melhor a parametrização do
software deles.


** Agosto
*** Semana 1
**** Resumo executivo
**** Notas completas

***** Reunião Geyer e Julio

Em reunião com Geyer e Julio optamos por focar o trabalho na redução
do uso de memória de outro software utilizado no pipeline de análise
genética empregado no mestrado da Agnis, o esforço para paralelizar em
GPU a implementação do BFGS do slimcodeml sendo grande demais e os
resultados incertos demais para o tamanho dos dados.

***** Estudo do ANGSD

O software em questão é o ANGSD. Link do drive fornecido pelo Julio:
https://drive.google.com/drive/folders/138CKIh88pqT7TihLaUPn8bJlua5WlSsi

Mais links do software:

Paper: https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-014-0356-4
Código: https://github.com/ANGSD/angsd
Wiki: http://www.popgen.dk/angsd/index.php/ANGSD

A ferramenta depende de outra de código aberto, HTSlib:

Paper: https://doi.org/10.1093/gigascience/giab007
Código: https://github.com/samtools/htslib

O objetivo do estudo é realizar um teste chamado Population Branch
Statistic (PBS) para determinar se a genética de uma população
influencia em alguma característica específica, como o uso de uma
língua tonal (em que a entonação das palavras muda seu significado).

Para isso, utiliza-se uma comparação dos genomas chamada pairwise fst.

Arquivo .BAM é uma versão binária do arquivo SAM - sequence alignment
map.

A entrada do programa consiste de vários arquivos. No caso de uso aqui
são três pop1.filelist ao pop3.filelist listando nossas entradas BAM,
e um arquivo chamado =GRCh38_full_analysis_set_plus_decoy_hla.fa= que
é público e necessário à análise:

#+BEGIN_EXAMPLE
./angsd -bam pop1.filelist -doSaf 1 -out pop1 -anc
GRCh38_full_analysis_set_plus_decoy.fa -GL 2 -P 4 -minMapQ 1 -minQ 20
$ ./angsd -bam pop2.filelist -doSaf 1 -out pop2 -anc
GRCh38_full_analysis_set_plus_decoy.fa -GL 2 -P 4 -minMapQ 1 -minQ 20
$ ./angsd -bam pop3.filelist -doSaf 1 -out pop3 -anc
GRCh38_full_analysis_set_plus_decoy.fa -GL 2 -P 4 -minMapQ 1 -minQ 20
#+END_EXAMPLE

Essa etapa leva cerca de um dia para cada arquivo e porventura gera
problemas com uso de memória.

Na próxima etapa do pipeline é utilizada uma outra ferramenta contida
no angsd, chamada realSFS (dentro da pasta misc/, gerado pelo make
normal), o input sendo os arquivos da etapa anterior.

Wiki: http://www.popgen.dk/angsd/index.php/SFS_Estimation
Método numérico: http://www.popgen.dk/angsd/index.php/RealSFSmethod
Paper: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0037558

Essa etapa nunca é finalizada por uso de memória excessivo, mas
estima-se que leva mais de um dia para execução.

#+BEGIN_EXAMPLE
$ ./misc/realSFS pop1.saf.idx pop2.saf.idx -P 12 > pop1.pop2.ml
$ ./misc/realSFS pop1.saf.idx pop3.saf.idx -P 12 > pop1.pop3.ml
$ ./misc/realSFS pop2.saf.idx pop3.saf.idx -P 12 > pop2.pop3.ml
#+END_EXAMPLE

Nessa etapa o realSFS.cpp roda =main_opt<float>(arg)=.

As demais etapas usam o realSFS mas não foram testadas devido ao
problema de memória.

#+BEGIN_EXAMPLE
$ ./misc/realSFS fst index pop1.saf.idx pop2.saf.idx pop3.saf.idx
-fstout pop1.pop2.pop3 -sfs pop1.pop2.ml -sfs pop1.pop3.ml -sfs
pop2.pop3.ml
#+END_EXAMPLE

#+BEGIN_EXAMPLE
$ ./misc/realSFS fst stats2 pop1.pop2.pop3.fst.idx -win 50000 -step
10000 >SlidingWindowBackground
#+END_EXAMPLE

O realSFS implementa BFGS também! Parece ser uma adaptação deste:
http://users.iems.northwestern.edu/~nocedal/lbfgsb.html. Supostamente é thread-safe:

#+BEGIN_EXAMPLE
/*
  mod by thorfinn@binf.ku.dk 7 nov 2011.

  The code looks like fortran 2 c translated program of v 2.1
  http://users.eecs.northwestern.edu/~nocedal/lbfgsb.html

  1) Fixed a bug concerning non-consistency in the optimized parameters (accecing noninitialized values)
  2) Is now thread safe. (removed local static variables)
  3) Added a "data" paramater to the findmax_bfgs, such that global variables can be avoided
  4) modified code such that it is c and c++ compilable.
 */
#+END_EXAMPLE

Mas na verdade somente em uma versão antiga... O otimizador atualmente
utilizado parece ser "Electromagnetism-like Mechanism".

#+BEGIN_EXAMPLE
We can find the MLE of the SFS by using either an BFGS approach that
uses derivatives or by using en EM algorithm. Both is implemented in
the realSFS program.
#+END_EXAMPLE

#+BEGIN_EXAMPLE
afarah@gentoopc ~/tcc/alef/angsd $ fgrep -re findmax_bfgs
misc/fpsmc.cpp:  double max_llh = findmax_bfgs(tk_l,pars,(void *)&data,qFunction,NULL,lbd,ubd,nbd,1);
misc/realSFS.old.cpp:    fnmax= findmax_bfgs( dim-1, p,NULL, lik1_bfgs, lik1_grad_bfgs_master, min, max, nbd, noisy );  
misc/realSFS.old.cpp:    fnmax= findmax_bfgs( dim-1, p,NULL, lik1_bfgs,NULL, min, max, nbd, noisy );  
bfgs.h:  3) Added a "data" paramater to the findmax_bfgs, such that global variables can be avoided
bfgs.h:double findmax_bfgs(int numpars, double *invec,const void*dats, double (*fun)(const double x[],const void*),
bfgs.cpp:double findmax_bfgs(int numpars, double *invec,const void*dats, double (*fun)(const double x[],const void*),
grep: .bfgs.cpp.swp: binary file matches
abcError.cpp:  double res=findmax_bfgs(12,start,(void *)es,likeFixedMinorError_wrapper_tsk,NULL,lbound,ubound,lims,-1);
afarah@gentoopc ~/tcc/alef/angsd/misc $ grep -rPe '\bem\('
ngsPSMC.cpp:double em(double &x,double *gls,int nSites,double tol){
ngsPSMC.cpp:  double llh = em(opt,gls,at,1e-8);
realSFS_optim.cpp:double em(double *sfs,double tole,int maxIter,int nThreads,int dim,std::vector<Matrix<T> *> &gls,int verbose){
ngsadmix32.cpp:void em(double** Q, double** F, int nSites, int nInd, int K,double **genos,double **F_1,double **Q_1) {
ngsadmix32.cpp:  em(Q, F, d.nSites, d.nInd, nPop,d.genos,F_em1,Q_em1);
ngsadmix32.cpp:  em(Q_em1, F_em1, d.nSites, d.nInd, nPop,d.genos,F_em2,Q_em2);
ngsadmix32.cpp:    em(*Q_new, *F_new, d.nSites, d.nInd, nPop,d.genos,F_tmp,Q_tmp);
ngsadmix32.cpp: em(Q, F, d.nSites, d.nInd, nPop,d.genos,F_new,Q_new);
ngsadmix32.cpp:    em(NULL, NULL, 0, 0, 0,NULL,NULL,NULL);
#+END_EXAMPLE

=main_opt=, que vimos acima é o que roda quando chamado com os params da Agnis, chama o em:

#+BEGIN_EXAMPLE
      if(arg->emAccl==0)
	lik = em<float>(sfs,arg->tole,arg->maxIter,arg->nThreads,ndim,gls,arg->verbose);
      else
	lik = emAccl<float>(sfs,arg->tole,arg->maxIter,arg->nThreads,ndim,gls,arg->emAccl,arg->verbose);
#+END_EXAMPLE

Que por sua vez usa pthreads:

#+BEGIN_EXAMPLE
template<typename T>
void emStep_master(double *post,int nThreads){
  for(size_t i=0;i<nThreads;i++){
    int rc = pthread_create(&thd[i],NULL,emStep_slave<T>,(void*) i);
    if(rc)
      fprintf(stderr,"Error creating thread\n");
    
  }
  for(int i=0;i<nThreads;i++)
    pthread_join(thd[i], NULL);
    
  memcpy(post,emp[0].post,emp[0].dim*sizeof(double));
  for(int i=1;i<nThreads;i++){
    for(int j=0;j<emp[0].dim;j++)
      post[j] += emp[i].post[j];
  }
  
  for(int j=0;j<emp[0].dim;j++)
    if(bootnSites)
      post[j] /= double(bootnSites);
    else
      post[j] /= double(emp[0].gls[0]->x);//nspope; rescale *after* threads have merged

#if 0
  for(int i=0;i<nThreads;i++){
    for(int j=0;j<dim;j++)
      fprintf(stdout,"%f ",emp[i].post[j]);
    fprintf(stdout,"\n");
  }
#endif
  
}
#+END_EXAMPLE

#+BEGIN_EXAMPLE
template <typename T>
void *emStep_slave(void *p){
  emPars<T> &pars = emp[(size_t) p];
  if(pars.gls.size()==1)
    emStep1<T>(pars.sfs,pars.gls,pars.post,pars.from,pars.to,pars.dim,pars.inner);
  else if(pars.gls.size()==2)
    emStep2<T>(pars.sfs,pars.gls,pars.post,pars.from,pars.to,pars.dim,pars.inner);
  else if(pars.gls.size()==3)
    emStep3<T>(pars.sfs,pars.gls,pars.post,pars.from,pars.to,pars.dim,pars.inner);
  else if(pars.gls.size()==4)
    emStep4<T>(pars.sfs,pars.gls,pars.post,pars.from,pars.to,pars.dim,pars.inner);
  pthread_exit(NULL);
}
#+END_EXAMPLE

#+BEGIN_EXAMPLE
template <typename T>
void emStep1(double *pre,std::vector< Matrix<T> * > &gls,double *post,size_t start,size_t stop,int dim,double *inner){
  for(int x=0;x<dim;x++)
    post[x] =0.0;
    
  for(size_t s=start;SIG_COND&&s<stop;s++){
    if(bootstrap==NULL){
      for(int i=0;i<dim;i++)
	inner[i] =0;
      for(int x=0;x<dim;x++)
	inner[foldremapper[x]] += pre[foldremapper[x]]*gls[0]->mat[s][x]*foldfactors[x];
    }else{
      for(int i=0;i<dim;i++)
	inner[i] =0;
      for(int x=0;x<dim;x++)
	inner[foldremapper[x]] += pre[foldremapper[x]]*gls[0]->mat[bootstrap[s]][x]*foldfactors[x];
    }
   normalize(inner,dim);
   for(int x=0;x<dim;x++)
     post[x] += inner[x];
  }
 
}


template <typename T>
void emStep2(double *pre,std::vector<Matrix<T> *> &gls,double *post,size_t start,size_t stop,int dim,double *inner){
  for(int x=0;x<dim;x++)
    post[x] =0.0;
   
  if(bootstrap==NULL)
    for(size_t s=start;SIG_COND&&s<stop;s++){
      int inc=0;
      for(int i=0;i<dim;i++)
	inner[i] =0;
      for(size_t x=0;x<gls[0]->y;x++)
	for(size_t y=0;y<gls[1]->y;y++){
	  inner[foldremapper[inc]] += pre[foldremapper[inc]]*gls[0]->mat[s][x]*gls[1]->mat[s][y]*foldfactors[inc];
	  assert(!std::isnan(inner[foldremapper[inc]]));
	  inc++;
	}
      normalize(inner,dim);
      for(int x=0;x<dim;x++)
	post[x] += inner[x];
    }
  else
    for(size_t s=start;SIG_COND&&s<stop;s++){
      int inc=0;
      for(int i=0;i<dim;i++)
	inner[i] =0;
      for(size_t x=0;x<gls[0]->y;x++)
	for(size_t y=0;y<gls[1]->y;y++){
	  inner[foldremapper[inc]] += pre[foldremapper[inc]]*gls[0]->mat[bootstrap[s]][x]*gls[1]->mat[bootstrap[s]][y]*foldfactors[inc];
	  inc++;
	}
      normalize(inner,dim);
      for(int x=0;x<dim;x++)
	post[x] += inner[x];
    }

 
}

template <typename T>
void emStep3(double *pre,std::vector<Matrix<T> *> &gls,double *post,size_t start,size_t stop,int dim,double *inner){
  for(int x=0;x<dim;x++)
    post[x] =0.0;
  if(bootstrap==NULL)
  for(size_t s=start;SIG_COND&&s<stop;s++){
    int inc=0;
    for(size_t x=0;x<gls[0]->y;x++)
      for(size_t y=0;y<gls[1]->y;y++)
	for(size_t i=0;i<gls[2]->y;i++){
	  inner[inc] = pre[inc]*gls[0]->mat[s][x] * gls[1]->mat[s][y] * gls[2]->mat[s][i];
	  inc++;
	}
   normalize(inner,dim);
   for(int x=0;x<dim;x++)
     post[x] += inner[x];
  }
  else
  for(size_t s=start;SIG_COND&&s<stop;s++){
    int inc=0;
    for(size_t x=0;x<gls[0]->y;x++)
      for(size_t y=0;y<gls[1]->y;y++)
	for(size_t i=0;i<gls[2]->y;i++){
	  inner[inc] = pre[inc]*gls[0]->mat[bootstrap[s]][x] * gls[1]->mat[bootstrap[s]][y] * gls[2]->mat[bootstrap[s]][i];
	  inc++;
	}
   normalize(inner,dim);
   for(int x=0;x<dim;x++)
     post[x] += inner[x];
  }
   
}

template <typename T>
void emStep4(double *pre,std::vector<Matrix<T> *> &gls,double *post,size_t start,size_t stop,int dim,double *inner){

  for(int x=0;x<dim;x++)
    post[x] =0.0;
  if(bootstrap==NULL){
    for(size_t s=start;SIG_COND&&s<stop;s++){
      int inc=0;
      for(size_t x=0;x<gls[0]->y;x++)
	for(size_t y=0;y<gls[1]->y;y++)
	  for(size_t i=0;i<gls[2]->y;i++)
	    for(size_t j=0;j<gls[3]->y;j++){
	      inner[inc] = pre[inc]*gls[0]->mat[s][x] * gls[1]->mat[s][y] * gls[2]->mat[s][i]* gls[3]->mat[s][j];
	      inc++;
	    }
      normalize(inner,dim);//nspope; normalization/addition should happen for each site
      for(int x=0;x<dim;x++)
        post[x] += inner[x];
    }
  }
  else{
    for(size_t s=start;SIG_COND&&s<stop;s++){
      int inc=0;
      for(size_t x=0;x<gls[0]->y;x++)
	for(size_t y=0;y<gls[1]->y;y++)
	  for(size_t i=0;i<gls[2]->y;i++)
	    for(size_t j=0;j<gls[3]->y;j++){
	      inner[inc] = pre[inc]*gls[0]->mat[bootstrap[s]][x] * gls[1]->mat[bootstrap[s]][y] * gls[2]->mat[bootstrap[s]][i]* gls[3]->mat[bootstrap[s]][j];
	      inc++;
	    }
    normalize(inner,dim);//nspope; normalization/addition should happen for each site
    for(int x=0;x<dim;x++)
      post[x] += inner[x];
    }
  }
   
}
#+END_EXAMPLE

Uma função para ficar de olho (talvez possa ser re-aproveitado o
resultado de chamada anterior), de header.cpp:

#+BEGIN_EXAMPLE
void normalize(double *tmp,size_t len){
  double s=0;
  for(size_t i=0;i<len;i++)
    s += tmp[i];
  for(size_t i=0;i<len;i++)
    tmp[i] /=s;
}
#+END_EXAMPLE

Um trecho relevante relativo a alocação de memória é no main_opt de
realSFS_optim.cpp:

#+BEGIN_EXAMPLE
  std::vector<persaf *> &saf =arg->saf;
  for(int i=0;i<saf.size();i++)
    assert(saf[i]->pos!=NULL&&saf[i]->saf!=NULL);
  size_t nSites = arg->nSites;
  if(nSites == 0){//if no -nSites is specified
    nSites=calc_nsites(saf,arg);
  }
  if(fsizes<T>(saf,nSites)>getTotalSystemMemory())
    fprintf(stderr,"\t-> Looks like you will allocate too much memory, consider starting the program with a lower -nSites argument\n"); 
    
  fprintf(stderr,"\t-> nSites: %lu\n",nSites);
  float bytes_req_megs =(float) fsizes<T>(saf,nSites)/1024/1024;
  float mem_avail_megs =(float) getTotalSystemMemory()/1024/1024;//in percentile
  //fprintf(stderr,"en:%zu to:%f\n",bytes_req_megs,mem_avail_megs);
  fprintf(stderr,"\t-> The choice of -nSites will require atleast: %f megabyte memory, that is at least: %.2f%% of total memory\n",bytes_req_megs,bytes_req_megs*100/mem_avail_megs);
#+END_EXAMPLE

Papers a respeito do EM:

https://ieeexplore.ieee.org/document/5636954/
https://link.springer.com/article/10.1023/A:1022452626305
https://www.sciencedirect.com/science/article/pii/S1532046415000192o
www.academia.edu/download/30818603/pub2.pdf / https://github.com/mkozturk/em-optimizer

Assim que conseguir os dados de entrada com a Agnis pretendo neste fim
de semana rodar o angsd e o realSFS em uma das entradas para
determinar o tempo total de execução de cada um na Thor. Após isso,
pretendo perfilar o realSFS com massif gerando uma xtree para
visualização no kcachegrind:

https://valgrind.org/docs/manual/ms-manual.html

Caso a Agnis já tenha os dados de entrada do realSFS seria melhor para
mim pois acelera o processo.

Pelo que li limitar o número de sites e outros parâmetros que poderiam
reduzir a alocação de memória reduzem também a acurácia do resultado:

http://www.popgen.dk/angsd/index.php/RealSFS

Talvez rodar com menos threads ajude, mas tem que considerar o impacto
de performance daí.

Há várias issues relatando segfaults e outros problemas, mas a maioria
no angsd em si e não no realSFS:

https://github.com/ANGSD/angsd/issues

***** Infraestrutura a usar

Agnis comentou que seria necessário cerca de 1TB de espaço para
armazenar os dados de entrada. No meu computador pessoal não tenho nem
perto disso disponível. Na Thor1 tem 390GB:

#+BEGIN_EXAMPLE
gppd1@THOR-01:~$ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev             32G     0   32G   0% /dev
tmpfs           6,3G  1,9M  6,3G   1% /run
/dev/sda2       457G   44G  391G  11% /
tmpfs            32G     0   32G   0% /dev/shm
tmpfs           5,0M  4,0K  5,0M   1% /run/lock
tmpfs            32G     0   32G   0% /sys/fs/cgroup
/dev/loop0      100M  100M     0 100% /snap/core/11316
/dev/loop2       56M   56M     0 100% /snap/core18/2066
/dev/loop3       56M   56M     0 100% /snap/core18/2074
/dev/loop4       62M   62M     0 100% /snap/core20/1026
/dev/loop5       62M   62M     0 100% /snap/core20/1081
/dev/loop6      163M  163M     0 100% /snap/gnome-3-28-1804/145
/dev/loop7      165M  165M     0 100% /snap/gnome-3-28-1804/161
/dev/loop8      219M  219M     0 100% /snap/gnome-3-34-1804/66
/dev/loop9      219M  219M     0 100% /snap/gnome-3-34-1804/72
/dev/loop10     244M  244M     0 100% /snap/gnome-3-38-2004/39
/dev/loop11     2,5M  2,5M     0 100% /snap/gnome-system-monitor/160
/dev/loop12     2,5M  2,5M     0 100% /snap/gnome-system-monitor/163
/dev/loop13      65M   65M     0 100% /snap/gtk-common-themes/1514
/dev/loop14      66M   66M     0 100% /snap/gtk-common-themes/1515
/dev/loop15      51M   51M     0 100% /snap/snap-store/542
/dev/loop16      51M   51M     0 100% /snap/snap-store/547
/dev/sda1       511M  7,9M  504M   2% /boot/efi
tmpfs           6,3G   20K  6,3G   1% /run/user/121
/dev/loop17     100M  100M     0 100% /snap/core/11420
tmpfs           6,3G  4,0K  6,3G   1% /run/user/1001
#+END_EXAMPLE

No scratch da beagle tem 705GB e no NFS tem 6.2TB:

#+BEGIN_EXAMPLE
afarah@beagle:~$ df -h
Filesystem          Size  Used Avail Use% Mounted on
udev                 16G     0   16G   0% /dev
tmpfs               3.2G  322M  2.9G  11% /run
/dev/sda1            92G  9.0G   78G  11% /
tmpfs                16G     0   16G   0% /dev/shm
tmpfs               5.0M     0  5.0M   0% /run/lock
tmpfs                16G     0   16G   0% /sys/fs/cgroup
/dev/sda6           822G   76G  705G  10% /scratch
192.168.30.2:/home   22T   16T  6.2T  72% /home
tmpfs               3.2G     0  3.2G   0% /run/user/1127
#+END_EXAMPLE

Julio irá criar uma conta na CEI para mim onde há 300TB, na segunda.

***** Reunião com Agnis

Em reunião com a Agnis, ela explicou que antes do pipeline de análise
descrito no drive é preciso obter e tratar alguns arquivos para
entrada. Nomeadamente, ela está obtendo arquivos com o genoma da
população do Vietnam, Camboja, e França, p.e. de 6 indivíduos de cada
país, do internationalgenome.org. São os arquivos .cram. Então,
converte para .bam usando um software chamado samtools e um genoma de
referência GRCh38, obtido do ftp do 1000genomes.ebi.ac.uk, o arquivo
.fa:

1. Baixar os .cram (p.e. 6 para cada uma das 3 pops)
2. Converter para .bam usando o samtools e o genoma de ref. GRCh38 .fa
3. Começa a usar o angsd cf. pipeline descrito no drive.

Ela explicou também que há uma via de análise alternativa ao uso do
angsd, mas que é bem demorada, que é transformar o .bam em um .vcf
usando o samtools e bcftools para análise posterior usando R.

O comando do samtools para converter os .cram para .bam é:

#+BEGIN_EXAMPLE
samtools view -b -T <refgenome.fa> -o <file.bam> <file.cram>
#+END_EXAMPLE

Depois disso é preciso outro comando para filtrar:

#+BEGIN_EXAMPLE
samtools view -b cal1.bam chr{1..22} >cal-sub-1.bam
samtools view -b input.bam chr{1..22} >file.bam
#+END_EXAMPLE

A Agnis ficou de disponibilizar possivelmente até segunda um
fluxograma do pipeline de análise completo. Acredito que a
contribuição maior desse trabalho seja a melhoria desse pipeline, e
por isso acho importante termos essa visão.

Agnis compartilhou comigo um arquivo .py (agnis/pipeline.py) não
completamente testado que usa o samtools para produzir o vcf.
     
***** Estudo do samtools

https://en.wikipedia.org/wiki/SAMtools      

A HTSlib usada pelo ANGSD é basicamente uma API do SAMTools.

BCFTools é parte do SAMTools.

http://www.htslib.org/

Atualmente SAM e BCF usam o HTS internamente.

https://pubmed.ncbi.nlm.nih.gov/33590861/

https://en.wikipedia.org/wiki/Variant_Call_Format

Interessante do artigo acima:

#+BEGIN_EXAMPLE
In particular, there is rarely any need to convert SAM to BAM using
“samtools view -b” be- fore running commands like “samtools sort,”
although regret- tably this idiom still appears in a large number of
online tutori- als. We encourage readers to follow best practices and
workflows published at [12].
#+END_EXAMPLE

https://www.htslib.org/workflow/

Estou vendo com a Agnis como isso se encaixa no workflow dela. Outros pontos de interesse:

#+BEGIN_EXAMPLE
Thread support first arrived in version 0.1.19 (March 2013), which
enabled them for sorting and BAM file writing in the view command.

...

However, extremely big files are produced by large projects and their
processing requires a high degree of par- allelization on computing
clusters. Future versions of SAMtools and BCFtools are expected to
make more use of threaded code to allow faster processing of such
files.
#+END_EXAMPLE

Esse artigo é de 2021.

Em suma, o script da Agnis chama:

#+BEGIN_EXAMPLE
BAM=arquivo.bam
FA=arquivo.fa
samtools view -b -T $FA $BAM 
if $(samtools view -h $BAM | grep coordinate)
then
  samtools sort -o $BAM.sorted $BAM 
  BAM=$BAM.sorted
fi
samtools index $BAM
for i in {1..23}
do
  OUT=chr$i
  samtools view -b $BAM chr $i >$OUT.bam
  samtools index $OUT.bam
  # ???  samtools merge 
  bcftools mpileup -O -b -o $OUT.bcf -f $FA $OUT.bam
  bcftools call -m -u -o call $OUT.bcf $OUT.BCF # ????
  bcftools view call $OUT.bcf | vcfutils.pl varFilter - > final$OUT.vcf # ????
done
#+END_EXAMPLE

Uma ideia então é trabalhar com um único .bam e testar ambos fluxos,
pelo samtools e pelo angsd, avaliando tanto melhorias de workflow como
melhorias de código via perfilamento.

* Referências

[1] Yang 2000: Codon-Substitution Models for Detecting Molecular Adaptation at Individual Sites Along Specific Lineages
https://academic.oup.com/mbe/article/19/6/908/1094851

[2] Manual do PAML: http://abacus.gene.ucl.ac.uk/software/pamlDOC.pdf

[3] Yun Fei 2014: Parallel L-BFGS-B Algorithm on GPU
https://www.sciencedirect.com/science/article/abs/pii/S0097849314000119
https://github.com/nepluno/lbfgsb-gpu

[4] Mario Valle 2012: SlimCodeML: An Optimized Version of CodeML for the Branch-Site Model
https://ieeexplore.ieee.org/document/6270710
ftp://ftp.selectome.org/Tools/SlimCodeML/Slimcodeml_2014_02_11.zip

[5] Mario Valle 2014: Optimization strategies for fast detection of positive selection on phylogenetic trees
https://pubmed.ncbi.nlm.nih.gov/24389654/
https://gitlab.sib.swiss/phylo/fastcodeml


* Literatura interessante

  (!) !!!!!!!!!!!!!!!!!!!!
  gcodeml: A Grid-enabled Tool for Detecting Positive Selection in Biological Evolution
http://arxiv.org/pdf/1203.3092.pdf

Although the codeml algorithm is currently supporting an embarrassingly parallel
approach, codeml does not yet make use of data-parallel features to allow for better
performance of single runs. In a related project (http://www.hp2c.ch/projects/selectome/)
we are currently improving both the algorithm and the implementation of the codon
model used in Selectome. If the run-time of the codeml executable is improved, this also
has a positive impact on the number of Grid and/or cluster calculations that are required
to produce new versions of Selectome since many nodes are now multi-core.

-> http://www.hp2c.ch/projects/selectome/

[a] Yang 2000 Statistical methods for detecting molecular adaptation
 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7134603/

* Outros links

https://github.com/abacus-gene/paml
https://github.com/ziheng-yang
https://en.wikipedia.org/wiki/Ziheng_Yang
http://abacus.gene.ucl.ac.uk/
http://abacus.gene.ucl.ac.uk/people/

Ziheng Yang
Professor, FRS
email: z.yang@ucl.ac.uk

https://www.google.com/search?q=codeml+site:www.biostars.org&sa=X&ved=2ahUKEwiw-5yv4MrxAhXTq5UCHVF3AaIQrQIoBHoECB0QBQ&biw=1920&bih=937
https://www.biostars.org/p/17045/
https://gist.github.com/mgalardini/3743820

